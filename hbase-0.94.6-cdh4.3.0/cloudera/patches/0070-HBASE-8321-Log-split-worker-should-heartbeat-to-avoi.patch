From 112d523233038b01471393ea58379fed84e20518 Mon Sep 17 00:00:00 2001
From: Jimmy Xiang <jxiang@cloudera.com>
Date: Tue, 16 Apr 2013 14:46:34 -0700
Subject: [PATCH 70/96] HBASE-8321 Log split worker should heartbeat to avoid timeout when the hlog is under recovery

Reason: Bug
Author: Jimmy Xiang
Ref: CDH-11180
---
 .../hadoop/hbase/regionserver/SplitLogWorker.java  |   22 +++-
 .../apache/hadoop/hbase/regionserver/wal/HLog.java |   12 ++-
 .../hbase/regionserver/wal/HLogSplitter.java       |  116 +++++++++-----------
 .../org/apache/hadoop/hbase/util/FSHDFSUtils.java  |    8 +-
 .../org/apache/hadoop/hbase/util/FSMapRUtils.java  |    6 +-
 .../java/org/apache/hadoop/hbase/util/FSUtils.java |    3 +-
 .../apache/hadoop/hbase/util/RegionSplitter.java   |    2 +-
 .../hbase/master/TestDistributedLogSplitting.java  |    1 +
 .../hadoop/hbase/regionserver/wal/TestHLog.java    |    2 +-
 .../hbase/regionserver/wal/TestHLogSplit.java      |   45 +++++++-
 10 files changed, 134 insertions(+), 83 deletions(-)

diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java b/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java
index 0dbc4f9..ddcab52 100644
--- a/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java
+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/SplitLogWorker.java
@@ -34,6 +34,7 @@ import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hbase.master.SplitLogManager;
 import org.apache.hadoop.hbase.regionserver.wal.HLogSplitter;
 import org.apache.hadoop.hbase.util.CancelableProgressable;
+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
 import org.apache.hadoop.hbase.util.FSUtils;
 import org.apache.hadoop.hbase.zookeeper.ZKSplitLog;
 import org.apache.hadoop.hbase.zookeeper.ZKSplitLog.TaskState;
@@ -71,7 +72,6 @@ public class SplitLogWorker extends ZooKeeperListener implements Runnable {
   Thread worker;
   private final String serverName;
   private final TaskExecutor splitTaskExecutor;
-  private long zkretries;
 
   private Object taskReadyLock = new Object();
   volatile int taskReadySeq = 0;
@@ -80,14 +80,17 @@ public class SplitLogWorker extends ZooKeeperListener implements Runnable {
   private volatile boolean exitWorker;
   private Object grabTaskLock = new Object();
   private boolean workerInGrabTask = false;
-
+  private final int report_period;
 
   public SplitLogWorker(ZooKeeperWatcher watcher, Configuration conf,
       String serverName, TaskExecutor splitTaskExecutor) {
     super(watcher);
     this.serverName = serverName;
     this.splitTaskExecutor = splitTaskExecutor;
-    this.zkretries = conf.getLong("hbase.splitlog.zk.retries", 3);
+
+    report_period = conf.getInt("hbase.splitlog.report.period",
+      conf.getInt("hbase.splitlog.manager.timeout",
+        ZKSplitLog.DEFAULT_TIMEOUT) / 3);
   }
 
   public SplitLogWorker(ZooKeeperWatcher watcher, final Configuration conf,
@@ -280,15 +283,22 @@ public class SplitLogWorker extends ZooKeeperListener implements Runnable {
       status = splitTaskExecutor.exec(ZKSplitLog.getFileName(currentTask),
           new CancelableProgressable() {
 
+        private long last_report_at = 0;
+
         @Override
         public boolean progress() {
-          if (attemptToOwnTask(false) == false) {
-            LOG.warn("Failed to heartbeat the task" + currentTask);
-            return false;
+          long t = EnvironmentEdgeManager.currentTimeMillis();
+          if ((t - last_report_at) > report_period) {
+            last_report_at = t;
+            if (!attemptToOwnTask(false)) {
+              LOG.warn("Failed to heartbeat the task" + currentTask);
+              return false;
+            }
           }
           return true;
         }
       });
+
       switch (status) {
         case DONE:
           endTask(TaskState.TASK_DONE, tot_wkr_task_done);
diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java b/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java
index b32d100..c35d920 100644
--- a/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java
+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java
@@ -67,6 +67,7 @@ import org.apache.hadoop.hbase.HTableDescriptor;
 import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.ServerName;
 import org.apache.hadoop.hbase.util.Bytes;
+import org.apache.hadoop.hbase.util.CancelableProgressable;
 import org.apache.hadoop.hbase.util.ClassSize;
 import org.apache.hadoop.hbase.util.FSUtils;
 import org.apache.hadoop.hbase.util.HasThread;
@@ -715,8 +716,12 @@ public class HLog implements Syncable {
    * @throws IOException
    */
   public static Reader getReader(final FileSystem fs, final Path path,
-                                 Configuration conf)
-      throws IOException {
+      Configuration conf) throws IOException {
+    return getReader(fs, path, conf, null);
+  }
+
+  public static Reader getReader(final FileSystem fs, final Path path,
+        Configuration conf, CancelableProgressable reporter) throws IOException {
     if (logReaderClass == null) {
       logReaderClass = conf.getClass("hbase.regionserver.hlog.reader.impl",
         SequenceFileLogReader.class, Reader.class);
@@ -740,6 +745,9 @@ public class HLog implements Syncable {
             if (++nbAttempt == 1) {
               LOG.warn("Lease should have recovered. This is not expected. Will retry", e);
             }
+            if (reporter != null && !reporter.progress()) {
+              throw new InterruptedIOException("Operation is cancelled");
+            }
             if (nbAttempt > 2 && openTimeout < System.currentTimeMillis()) {
               LOG.error("Can't open after " + nbAttempt + " attempts and "
                 + (System.currentTimeMillis() - startWaiting)
diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java b/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java
index d745dce..59686e5 100644
--- a/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java
+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java
@@ -108,7 +108,6 @@ public class HLogSplitter {
   
   private MonitoredTask status;
 
-
   /**
    * Create a new HLogSplitter using the given {@link Configuration} and the
    * <code>hbase.hlog.splitter.impl</code> property to derived the instance
@@ -282,7 +281,7 @@ public class HLogSplitter {
             + ": " + logPath + ", length=" + logLength);
         Reader in;
         try {
-          in = getReader(fs, log, conf, skipErrors);
+          in = getReader(fs, log, conf, skipErrors, null);
           if (in != null) {
             parseHLog(in, logPath, entryBuffers, fs, conf, skipErrors);
             try {
@@ -356,54 +355,47 @@ public class HLogSplitter {
     final Map<byte[], Object> logWriters = Collections.
     synchronizedMap(new TreeMap<byte[], Object>(Bytes.BYTES_COMPARATOR));
     boolean isCorrupted = false;
-    
     Preconditions.checkState(status == null);
-    status = TaskMonitor.get().createStatus(
-        "Splitting log file " + logfile.getPath() +
-        "into a temporary staging area.");
 
     Object BAD_WRITER = new Object();
 
-    boolean progress_failed = false;
-
     boolean skipErrors = conf.getBoolean("hbase.hlog.split.skip.errors",
         HLog.SPLIT_SKIP_ERRORS_DEFAULT);
     int interval = conf.getInt("hbase.splitlog.report.interval.loglines", 1024);
-    // How often to send a progress report (default 1/2 the zookeeper session
-    // timeout of if that not set, the split log DEFAULT_TIMEOUT)
-    int period = conf.getInt("hbase.splitlog.report.period",
-      conf.getInt("hbase.splitlog.manager.timeout", ZKSplitLog.DEFAULT_TIMEOUT) / 2);
-    int numOpenedFilesBeforeReporting =
-      conf.getInt("hbase.splitlog.report.openedfiles", 3);
     Path logPath = logfile.getPath();
-    long logLength = logfile.getLen();
-    LOG.info("Splitting hlog: " + logPath + ", length=" + logLength);
-    status.setStatus("Opening log file");
-    Reader in = null;
-    try {
-      in = getReader(fs, logfile, conf, skipErrors);
-    } catch (CorruptedLogFileException e) {
-      LOG.warn("Could not get reader, corrupted log file " + logPath, e);
-      ZKSplitLog.markCorrupted(rootDir, logfile.getPath().getName(), fs);
-      isCorrupted = true;
-    }
-    if (in == null) {
-      status.markComplete("Was nothing to split in log file");
-      LOG.warn("Nothing to split in log file " + logPath);
-      return true;
-    }
-    long t = EnvironmentEdgeManager.currentTimeMillis();
-    long last_report_at = t;
-    if (reporter != null && reporter.progress() == false) {
-      status.markComplete("Failed: reporter.progress asked us to terminate");
-      return false;
-    }
-    // Report progress every so many edits and/or files opened (opening a file
-    // takes a bit of time).
+    boolean progress_failed = false;
     int editsCount = 0;
-    int numNewlyOpenedFiles = 0;
-    Entry entry;
+    Reader in = null;
+
     try {
+      status = TaskMonitor.get().createStatus(
+        "Splitting log file " + logfile.getPath() +
+        "into a temporary staging area.");
+      long logLength = logfile.getLen();
+      LOG.info("Splitting hlog: " + logPath + ", length=" + logLength);
+      status.setStatus("Opening log file");
+      if (reporter != null && !reporter.progress()) {
+        progress_failed = true;
+        return false;
+      }
+      try {
+        in = getReader(fs, logfile, conf, skipErrors, reporter);
+      } catch (CorruptedLogFileException e) {
+        LOG.warn("Could not get reader, corrupted log file " + logPath, e);
+        ZKSplitLog.markCorrupted(rootDir, logfile.getPath().getName(), fs);
+        isCorrupted = true;
+      }
+      if (in == null) {
+        status.markComplete("Was nothing to split in log file");
+        LOG.warn("Nothing to split in log file " + logPath);
+        return true;
+      }
+
+      int numOpenedFilesBeforeReporting =
+        conf.getInt("hbase.splitlog.report.openedfiles", 3);
+      int numNewlyOpenedFiles = 0;
+      Entry entry;
+
       while ((entry = getNextLogLine(in,logPath, skipErrors)) != null) {
         byte[] region = entry.getKey().getEncodedRegionName();
         Object o = logWriters.get(region);
@@ -434,14 +426,10 @@ public class HLogSplitter {
           numNewlyOpenedFiles = 0;
           String countsStr = "edits=" + editsCount + ", files=" + logWriters.size();
           status.setStatus("Split " + countsStr);
-          long t1 = EnvironmentEdgeManager.currentTimeMillis();
-          if ((t1 - last_report_at) > period) {
-            last_report_at = t;
-            if (reporter != null && reporter.progress() == false) {
-              status.markComplete("Failed: reporter.progress asked us to terminate; " + countsStr);
-              progress_failed = true;
-              return false;
-            }
+          if (reporter != null && reporter.progress() == false) {
+            status.markComplete("Failed: reporter.progress asked us to terminate; " + countsStr);
+            progress_failed = true;
+            return false;
           }
         }
       }
@@ -454,16 +442,12 @@ public class HLogSplitter {
       throw e;
     } finally {
       boolean allWritersClosed = false;
+      int n = 0;
       try {
-        int n = 0;
         for (Map.Entry<byte[], Object> logWritersEntry : logWriters.entrySet()) {
           Object o = logWritersEntry.getValue();
-          long t1 = EnvironmentEdgeManager.currentTimeMillis();
-          if ((t1 - last_report_at) > period) {
-            last_report_at = t;
-            if ((progress_failed == false) && (reporter != null) && (reporter.progress() == false)) {
-              progress_failed = true;
-            }
+          if ((progress_failed == false) && (reporter != null) && (reporter.progress() == false)) {
+            progress_failed = true;
           }
           if (o == BAD_WRITER) {
             continue;
@@ -495,12 +479,12 @@ public class HLogSplitter {
           }
         }
         allWritersClosed = true;
+      } finally {
         String msg = "Processed " + editsCount + " edits across " + n + " regions"
             + " threw away edits for " + (logWriters.size() - n) + " regions" + "; log file="
             + logPath + " is corrupted = " + isCorrupted + " progress failed = " + progress_failed;
         LOG.info(msg);
         status.markComplete(msg);
-      } finally {
         if (!allWritersClosed) {
           for (Map.Entry<byte[], Object> logWritersEntry : logWriters.entrySet()) {
             Object o = logWritersEntry.getValue();
@@ -517,7 +501,9 @@ public class HLogSplitter {
             }
           }
         }
-        in.close();
+        if (in != null) {
+          in.close();
+        }
       }
     }
     return !progress_failed;
@@ -732,7 +718,7 @@ public class HLogSplitter {
    * @throws CorruptedLogFile
    */
   protected Reader getReader(FileSystem fs, FileStatus file, Configuration conf,
-      boolean skipErrors)
+      boolean skipErrors, CancelableProgressable reporter)
       throws IOException, CorruptedLogFileException {
     Path path = file.getPath();
     long length = file.getLen();
@@ -747,9 +733,9 @@ public class HLogSplitter {
     }
 
     try {
-      FSUtils.getInstance(fs, conf).recoverFileLease(fs, path, conf);
+      FSUtils.getInstance(fs, conf).recoverFileLease(fs, path, conf, reporter);
       try {
-        in = getReader(fs, path, conf);
+        in = getReader(fs, path, conf, reporter);
       } catch (EOFException e) {
         if (length <= 0) {
           // TODO should we ignore an empty, not-last log file if skip.errors
@@ -765,8 +751,8 @@ public class HLogSplitter {
         }
       }
     } catch (IOException e) {
-      if (!skipErrors) {
-        throw e;
+      if (!skipErrors || e instanceof InterruptedIOException) {
+        throw e; // Don't mark the file corrupted if interrupted, or not skipErrors
       }
       CorruptedLogFileException t =
         new CorruptedLogFileException("skipErrors=true Could not open hlog " +
@@ -834,9 +820,9 @@ public class HLogSplitter {
   /**
    * Create a new {@link Reader} for reading logs to split.
    */
-  protected Reader getReader(FileSystem fs, Path curLogFile, Configuration conf)
-      throws IOException {
-    return HLog.getReader(fs, curLogFile, conf);
+  protected Reader getReader(FileSystem fs, Path curLogFile,
+      Configuration conf, CancelableProgressable reporter) throws IOException {
+    return HLog.getReader(fs, curLogFile, conf, reporter);
   }
 
   /**
diff --git a/src/main/java/org/apache/hadoop/hbase/util/FSHDFSUtils.java b/src/main/java/org/apache/hadoop/hbase/util/FSHDFSUtils.java
index 4186f0a..30f92e4 100644
--- a/src/main/java/org/apache/hadoop/hbase/util/FSHDFSUtils.java
+++ b/src/main/java/org/apache/hadoop/hbase/util/FSHDFSUtils.java
@@ -52,8 +52,8 @@ public class FSHDFSUtils extends FSUtils{
   public static final long LEASE_SOFTLIMIT_PERIOD = 60 * 1000;
 
   @Override
-  public void recoverFileLease(final FileSystem fs, final Path p, Configuration conf)
-  throws IOException{
+  public void recoverFileLease(final FileSystem fs, final Path p,
+      Configuration conf, CancelableProgressable reporter) throws IOException{
     if (!isAppendSupported(conf)) {
       LOG.warn("Running on HDFS without append enabled may result in data loss");
       return;
@@ -109,6 +109,10 @@ public class FSHDFSUtils extends FSUtils{
           throw new IOException("Failed to open " + p + " for append", e);
         }
       }
+      if (reporter != null && !reporter.progress()) {
+        throw new InterruptedIOException("Operation is cancelled");
+      }
+
       try {
         Thread.sleep(1000);
       } catch (InterruptedException ex) {
diff --git a/src/main/java/org/apache/hadoop/hbase/util/FSMapRUtils.java b/src/main/java/org/apache/hadoop/hbase/util/FSMapRUtils.java
index e70b0d4..920cc1c 100644
--- a/src/main/java/org/apache/hadoop/hbase/util/FSMapRUtils.java
+++ b/src/main/java/org/apache/hadoop/hbase/util/FSMapRUtils.java
@@ -32,9 +32,9 @@ import org.apache.commons.logging.LogFactory;
 public class FSMapRUtils extends FSUtils {
   private static final Log LOG = LogFactory.getLog(FSMapRUtils.class);
   
-  public void recoverFileLease(final FileSystem fs, final Path p, 
-      Configuration conf) throws IOException {
-    LOG.info("Recovering file " + p.toString() + 
+  public void recoverFileLease(final FileSystem fs, final Path p,
+      Configuration conf, CancelableProgressable reporter) throws IOException {
+    LOG.info("Recovering file " + p.toString() +
       " by changing permission to readonly");
     FsPermission roPerm = new FsPermission((short) 0444);
     fs.setPermission(p, roPerm);
diff --git a/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java b/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java
index 0f5d468..259fa93 100644
--- a/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java
+++ b/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java
@@ -129,6 +129,7 @@ public abstract class FSUtils {
    * @return output stream to the created file
    * @throws IOException if the file cannot be created
    */
+  @SuppressWarnings("deprecation")
   public static FSDataOutputStream create(FileSystem fs, Path path,
       FsPermission perm) throws IOException {
     return create(fs, path, perm, true);
@@ -948,7 +949,7 @@ public abstract class FSUtils {
    * @throws IOException
    */
   public abstract void recoverFileLease(final FileSystem fs, final Path p,
-      Configuration conf) throws IOException;
+      Configuration conf, CancelableProgressable reporter) throws IOException;
 
   /**
    * @param fs
diff --git a/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java b/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java
index 619a715..217a3d1 100644
--- a/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java
+++ b/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java
@@ -759,7 +759,7 @@ public class RegionSplitter {
     } else {
       LOG.debug("_balancedSplit file found. Replay log to restore state...");
       FSUtils.getInstance(fs, table.getConfiguration())
-        .recoverFileLease(fs, splitFile, table.getConfiguration());
+        .recoverFileLease(fs, splitFile, table.getConfiguration(), null);
 
       // parse split file and process remaining splits
       FSDataInputStream tmpIn = fs.open(splitFile);
diff --git a/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java b/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
index 823d7da..b54a526 100644
--- a/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
+++ b/src/test/java/org/apache/hadoop/hbase/master/TestDistributedLogSplitting.java
@@ -192,6 +192,7 @@ public class TestDistributedLogSplitting {
     for (HRegionInfo hri : regions) {
 
       Path tdir = HTableDescriptor.getTableDir(rootdir, table);
+      @SuppressWarnings("deprecation")
       Path editsdir =
         HLog.getRegionDirRecoveredEditsDir(HRegion.getRegionDir(tdir,
         hri.getEncodedName()));
diff --git a/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLog.java b/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLog.java
index 60f77a0..09f8a34 100644
--- a/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLog.java
+++ b/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLog.java
@@ -455,7 +455,7 @@ public class TestHLog  {
       public void run() {
           try {
             FSUtils.getInstance(fs, rlConf)
-              .recoverFileLease(recoveredFs, walPath, rlConf);
+              .recoverFileLease(recoveredFs, walPath, rlConf, null);
           } catch (IOException e) {
             exception = e;
           }
diff --git a/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLogSplit.java b/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLogSplit.java
index a7e4fd8..6115cc6 100644
--- a/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLogSplit.java
+++ b/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestHLogSplit.java
@@ -34,6 +34,7 @@ import java.util.List;
 import java.util.Map;
 import java.util.NavigableSet;
 import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.commons.logging.Log;
@@ -55,6 +56,7 @@ import org.apache.hadoop.hbase.LargeTests;
 import org.apache.hadoop.hbase.regionserver.HRegion;
 import org.apache.hadoop.hbase.regionserver.wal.HLog.Entry;
 import org.apache.hadoop.hbase.regionserver.wal.HLog.Reader;
+import org.apache.hadoop.hbase.regionserver.wal.HLogSplitter.CorruptedLogFileException;
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.hbase.util.CancelableProgressable;
 import org.apache.hadoop.hbase.util.Threads;
@@ -775,6 +777,45 @@ public class TestHLogSplit {
     }
   }
 
+  @Test
+  public void testTerminationAskedByReporter() throws IOException, CorruptedLogFileException {
+    generateHLogs(1, 10, -1);
+    FileStatus logfile = fs.listStatus(hlogDir)[0];
+    fs.initialize(fs.getUri(), conf);
+
+    final AtomicInteger count = new AtomicInteger();
+    
+    CancelableProgressable localReporter
+      = new CancelableProgressable() {
+        @Override
+        public boolean progress() {
+          count.getAndIncrement();
+          return false;
+        }
+      };
+
+    FileSystem spiedFs = Mockito.spy(fs);
+    Mockito.doAnswer(new Answer<FSDataInputStream>() {
+      public FSDataInputStream answer(InvocationOnMock invocation) throws Throwable {
+        Thread.sleep(1500); // Sleep a while and wait report status invoked
+        return (FSDataInputStream)invocation.callRealMethod();
+      }
+    }).when(spiedFs).open(Mockito.<Path>any(), Mockito.anyInt());
+
+    try {
+      conf.setInt("hbase.splitlog.report.period", 1000);
+      HLogSplitter s = new HLogSplitter(conf, hbaseDir, null, null, spiedFs);
+      boolean ret = s.splitLogFile(logfile, localReporter);
+      assertFalse("Log splitting should failed", ret);
+      assertTrue(count.get() > 0);
+    } catch (IOException e) {
+      fail("There shouldn't be any exception but: " + e.toString());
+    } finally {
+      // reset it back to its default value
+      conf.setInt("hbase.splitlog.report.period", 59000);
+    }
+  }
+
   /**
    * Test log split process with fake data and lots of edits to trigger threading
    * issues.
@@ -857,8 +898,8 @@ public class TestHLogSplit {
 
 
       /* Produce a mock reader that generates fake entries */
-      protected Reader getReader(FileSystem fs, Path curLogFile, Configuration conf)
-      throws IOException {
+      protected Reader getReader(FileSystem fs, Path curLogFile,
+          Configuration conf, CancelableProgressable reporter) throws IOException {
         Reader mockReader = Mockito.mock(Reader.class);
         Mockito.doAnswer(new Answer<HLog.Entry>() {
           int index = 0;
-- 
1.7.0.4

