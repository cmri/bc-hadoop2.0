From c04c2fea3ba64cd11c278fe94286c4eda3acfd84 Mon Sep 17 00:00:00 2001
From: Matteo Bertozzi <mbertozzi@apache.org>
Date: Thu, 2 May 2013 08:46:58 +0000
Subject: [PATCH 85/96] HBASE-8455 Update ExportSnapshot to reflect changes in HBASE-7419

git-svn-id: https://svn.apache.org/repos/asf/hbase/branches/0.94@1478300 13f79535-47bb-0310-9956-ffa450edef68

Reason: Bug
Author: Matteo Bertozzi
Ref: CDH-10583
---
 .../hadoop/hbase/snapshot/ExportSnapshot.java      |   17 +++--
 .../hadoop/hbase/snapshot/TestExportSnapshot.java  |   76 ++++++++++++++++---
 2 files changed, 74 insertions(+), 19 deletions(-)

diff --git a/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java b/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java
index 62f2bcb..46aea0f 100644
--- a/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java
+++ b/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java
@@ -46,6 +46,7 @@ import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.io.HFileLink;
 import org.apache.hadoop.hbase.io.HLogLink;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription;
+import org.apache.hadoop.hbase.regionserver.StoreFile;
 import org.apache.hadoop.hbase.snapshot.ExportSnapshotException;
 import org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils;
 import org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil;
@@ -154,7 +155,7 @@ public final class ExportSnapshot extends Configured implements Tool {
      */
     private Path getOutputPath(final Path inputPath) throws IOException {
       Path path;
-      if (HFileLink.isHFileLink(inputPath)) {
+      if (HFileLink.isHFileLink(inputPath) || StoreFile.isReference(inputPath)) {
         String family = inputPath.getParent().getName();
         String table = HFileLink.getReferencedTableName(inputPath.getName());
         String region = HFileLink.getReferencedRegionName(inputPath.getName());
@@ -183,10 +184,12 @@ public final class ExportSnapshot extends Configured implements Tool {
         if (inputStat == null) return false;
 
         // Verify if the output file exists and is the same that we want to copy
-        FileStatus outputStat = getFileStatus(outputFs, outputPath);
-        if (outputStat != null && sameFile(inputStat, outputStat)) {
-          LOG.info("Skip copy " + inputPath + " to " + outputPath + ", same file.");
-          return true;
+        if (outputFs.exists(outputPath)) {
+          FileStatus outputStat = outputFs.getFileStatus(outputPath);
+          if (sameFile(inputStat, outputStat)) {
+            LOG.info("Skip copy " + inputPath + " to " + outputPath + ", same file.");
+            return true;
+          }
         }
 
         context.getCounter(Counter.BYTES_EXPECTED).increment(inputStat.getLen());
@@ -295,7 +298,7 @@ public final class ExportSnapshot extends Configured implements Tool {
 
     private FSDataInputStream openSourceFile(final Path path) {
       try {
-        if (HFileLink.isHFileLink(path)) {
+        if (HFileLink.isHFileLink(path) || StoreFile.isReference(path)) {
           return new HFileLink(inputRoot, inputArchive, path).open(inputFs);
         } else if (isHLogLinkPath(path)) {
           String serverName = path.getParent().getName();
@@ -311,7 +314,7 @@ public final class ExportSnapshot extends Configured implements Tool {
 
     private FileStatus getFileStatus(final FileSystem fs, final Path path) {
       try {
-        if (HFileLink.isHFileLink(path)) {
+        if (HFileLink.isHFileLink(path) || StoreFile.isReference(path)) {
           HFileLink link = new HFileLink(inputRoot, inputArchive, path);
           return link.getFileStatus(fs);
         } else if (isHLogLinkPath(path)) {
diff --git a/src/test/java/org/apache/hadoop/hbase/snapshot/TestExportSnapshot.java b/src/test/java/org/apache/hadoop/hbase/snapshot/TestExportSnapshot.java
index dfd0a78..244d4ec 100644
--- a/src/test/java/org/apache/hadoop/hbase/snapshot/TestExportSnapshot.java
+++ b/src/test/java/org/apache/hadoop/hbase/snapshot/TestExportSnapshot.java
@@ -36,8 +36,11 @@ import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.FileUtil;
+import org.apache.hadoop.fs.FSDataOutputStream;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hbase.HBaseTestingUtility;
+import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.HColumnDescriptor;
 import org.apache.hadoop.hbase.HRegionInfo;
 import org.apache.hadoop.hbase.HTableDescriptor;
@@ -50,6 +53,8 @@ import org.apache.hadoop.hbase.client.HTable;
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.hbase.util.FSUtils;
 import org.apache.hadoop.hbase.util.Pair;
+import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription;
+import org.apache.hadoop.hbase.regionserver.HRegion;
 import org.apache.hadoop.hbase.snapshot.ExportSnapshot;
 import org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil;
 import org.apache.hadoop.mapreduce.Job;
@@ -109,18 +114,14 @@ public class TestExportSnapshot {
     admin.createTable(htd, null);
 
     // Take an empty snapshot
-    admin.disableTable(tableName);
     admin.snapshot(emptySnapshotName, tableName);
-    admin.enableTable(tableName);
 
     // Add some rows
     HTable table = new HTable(TEST_UTIL.getConfiguration(), tableName);
     TEST_UTIL.loadTable(table, FAMILY);
 
     // take a snapshot
-    admin.disableTable(tableName);
     admin.snapshot(snapshotName, tableName);
-    admin.enableTable(tableName);
   }
 
   @After
@@ -183,6 +184,56 @@ public class TestExportSnapshot {
   }
 
   /**
+   * Mock a snapshot with files in the archive dir,
+   * two regions, and one reference file.
+   */
+  @Test
+  public void testSnapshotWithRefsExportFileSystemState() throws Exception {
+    Configuration conf = TEST_UTIL.getConfiguration();
+
+    final byte[] tableWithRefsName = Bytes.toBytes("tableWithRefs");
+    final String snapshotName = "tableWithRefs";
+    final String TEST_FAMILY = Bytes.toString(FAMILY);
+    final String TEST_HFILE = "abc";
+
+    final SnapshotDescription sd = SnapshotDescription.newBuilder()
+        .setName(snapshotName).setTable(Bytes.toString(tableWithRefsName)).build();
+
+    FileSystem fs = TEST_UTIL.getHBaseCluster().getMaster().getMasterFileSystem().getFileSystem();
+    Path rootDir = TEST_UTIL.getHBaseCluster().getMaster().getMasterFileSystem().getRootDir();
+    Path archiveDir = new Path(rootDir, HConstants.HFILE_ARCHIVE_DIRECTORY);
+
+    HTableDescriptor htd = new HTableDescriptor(tableWithRefsName);
+    htd.addFamily(new HColumnDescriptor(TEST_FAMILY));
+
+    // First region, simple with one plain hfile.
+    HRegion r0 = HRegion.createHRegion(new HRegionInfo(htd.getName()), archiveDir,
+        conf, htd, null, true, true);
+    Path storeFile = new Path(new Path(r0.getRegionDir(), TEST_FAMILY), TEST_HFILE);
+    FSDataOutputStream out = fs.create(storeFile);
+    out.write(Bytes.toBytes("Test Data"));
+    out.close();
+    r0.close();
+
+    // Second region, used to test the split case.
+    // This region contains a reference to the hfile in the first region.
+    HRegion r1 = HRegion.createHRegion(new HRegionInfo(htd.getName()), archiveDir,
+        conf, htd, null, true, true);
+    out = fs.create(new Path(new Path(r1.getRegionDir(), TEST_FAMILY),
+        storeFile.getName() + '.' + r0.getRegionInfo().getEncodedName()));
+    out.write(Bytes.toBytes("Test Data"));
+    out.close();
+    r1.close();
+
+    Path tableDir = HTableDescriptor.getTableDir(archiveDir, tableWithRefsName);
+    Path snapshotDir = SnapshotDescriptionUtils.getCompletedSnapshotDir(snapshotName, rootDir);
+    FileUtil.copy(fs, tableDir, fs, snapshotDir, false, conf);
+    SnapshotDescriptionUtils.writeSnapshotInfo(sd, snapshotDir, fs);
+
+    testExportFileSystemState(tableWithRefsName, Bytes.toBytes(snapshotName), 2);
+  }
+
+  /**
    * Test ExportSnapshot
    */
   private void testExportFileSystemState(final byte[] tableName, final byte[] snapshotName,
@@ -213,7 +264,8 @@ public class TestExportSnapshot {
     final Path snapshotDir = new Path(".snapshot", Bytes.toString(snapshotName));
     verifySnapshot(hdfs, new Path(TEST_UTIL.getDefaultRootDirPath(), snapshotDir),
         fs, new Path(copyDir, snapshotDir));
-    verifyArchive(fs, copyDir, Bytes.toString(snapshotName));
+    verifyArchive(fs, copyDir, tableName, Bytes.toString(snapshotName));
+    FSUtils.logFileSystemState(hdfs, snapshotDir, LOG);
 
     // Remove the exported dir
     fs.delete(copyDir, true);
@@ -231,10 +283,11 @@ public class TestExportSnapshot {
   /*
    * Verify if the files exists
    */
-  private void verifyArchive(final FileSystem fs, final Path rootDir, final String snapshotName)
-      throws IOException {
-    final Path exportedSnapshot = new Path(rootDir, new Path(".snapshot", snapshotName));
-    final Path exportedArchive = new Path(rootDir, ".archive");
+  private void verifyArchive(final FileSystem fs, final Path rootDir,
+      final byte[] tableName, final String snapshotName) throws IOException {
+    final Path exportedSnapshot = new Path(rootDir,
+      new Path(HConstants.SNAPSHOT_DIR_NAME, snapshotName));
+    final Path exportedArchive = new Path(rootDir, HConstants.HFILE_ARCHIVE_DIRECTORY);
     LOG.debug(listFiles(fs, exportedArchive, exportedArchive));
     SnapshotReferenceUtil.visitReferencedFiles(fs, exportedSnapshot,
         new SnapshotReferenceUtil.FileVisitor() {
@@ -256,9 +309,8 @@ public class TestExportSnapshot {
         }
 
         private void verifyNonEmptyFile(final Path path) throws IOException {
-          LOG.debug(path);
-          assertTrue(fs.exists(path));
-          assertTrue(fs.getFileStatus(path).getLen() > 0);
+          assertTrue(path + " should exist", fs.exists(path));
+          assertTrue(path + " should not be empty", fs.getFileStatus(path).getLen() > 0);
         }
     });
   }
-- 
1.7.0.4

