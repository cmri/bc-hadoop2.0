From 8e8abc2419dc58b98e5c5b56150f5ca97e8464dc Mon Sep 17 00:00:00 2001
From: Matteo Bertozzi <mbertozzi@apache.org>
Date: Tue, 14 May 2013 15:26:18 +0000
Subject: [PATCH 92/96] HBASE-8516 FSUtils.create() fail with ViewFS

git-svn-id: https://svn.apache.org/repos/asf/hbase/branches/0.94@1482392 13f79535-47bb-0310-9956-ffa450edef68

Reason: Bug
Author: Matteo Bertozzi
Ref: CDH-10050
---
 .../org/apache/hadoop/hbase/HBaseFileSystem.java   |    5 +-
 .../java/org/apache/hadoop/hbase/io/FileLink.java  |    3 +-
 .../apache/hadoop/hbase/regionserver/wal/HLog.java |   31 +-------
 .../regionserver/wal/SequenceFileLogWriter.java    |    9 +-
 .../java/org/apache/hadoop/hbase/util/FSUtils.java |   81 ++++++++++++++++++++
 5 files changed, 93 insertions(+), 36 deletions(-)

diff --git a/src/main/java/org/apache/hadoop/hbase/HBaseFileSystem.java b/src/main/java/org/apache/hadoop/hbase/HBaseFileSystem.java
index 5f83231..6594d85 100644
--- a/src/main/java/org/apache/hadoop/hbase/HBaseFileSystem.java
+++ b/src/main/java/org/apache/hadoop/hbase/HBaseFileSystem.java
@@ -27,6 +27,7 @@ import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.fs.permission.FsPermission;
 import org.apache.hadoop.hbase.regionserver.wal.HLogFileSystem;
+import org.apache.hadoop.hbase.util.FSUtils;
 import org.apache.hadoop.hbase.util.Threads;
 
 /**
@@ -206,8 +207,8 @@ public abstract class HBaseFileSystem {
     boolean existsBefore = fs.exists(path);
     do {
       try {
-        return fs.create(path, perm, overwrite, fs.getConf().getInt("io.file.buffer.size", 4096),
-          fs.getDefaultReplication(), fs.getDefaultBlockSize(), null);
+        return fs.create(path, perm, overwrite, FSUtils.getDefaultBufferSize(fs),
+          FSUtils.getDefaultReplication(fs, path), FSUtils.getDefaultBlockSize(fs, path), null);
       } catch (IOException ioe) {
         lastIOE = ioe;
         if (existsBefore && !overwrite) throw ioe;// a legitimate exception
diff --git a/src/main/java/org/apache/hadoop/hbase/io/FileLink.java b/src/main/java/org/apache/hadoop/hbase/io/FileLink.java
index e04de85..dc910e6 100644
--- a/src/main/java/org/apache/hadoop/hbase/io/FileLink.java
+++ b/src/main/java/org/apache/hadoop/hbase/io/FileLink.java
@@ -33,6 +33,7 @@ import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.fs.PositionedReadable;
 import org.apache.hadoop.fs.Seekable;
+import org.apache.hadoop.hbase.util.FSUtils;
 
 /**
  * The FileLink is a sort of hardlink, that allows to access a file given a set of locations.
@@ -107,7 +108,7 @@ public class FileLink {
 
     public FileLinkInputStream(final FileSystem fs, final FileLink fileLink)
         throws IOException {
-      this(fs, fileLink, fs.getConf().getInt("io.file.buffer.size", 4096));
+      this(fs, fileLink, FSUtils.getDefaultBufferSize(fs));
     }
 
     public FileLinkInputStream(final FileSystem fs, final FileLink fileLink, int bufferSize)
diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java b/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java
index c3df62b..03ae1e2 100644
--- a/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java
+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java
@@ -401,7 +401,7 @@ public class HLog implements Syncable {
       }
     }
     this.blocksize = conf.getLong("hbase.regionserver.hlog.blocksize",
-        getDefaultBlockSize());
+        FSUtils.getDefaultBlockSize(this.fs, this.dir));
     // Roll at 95% of block size.
     float multi = conf.getFloat("hbase.regionserver.logroll.multiplier", 0.95f);
     this.logrollsize = (long)(this.blocksize * multi);
@@ -420,7 +420,7 @@ public class HLog implements Syncable {
     this.maxLogs = conf.getInt("hbase.regionserver.maxlogs", 32);
     this.minTolerableReplication = conf.getInt(
         "hbase.regionserver.hlog.tolerable.lowreplication",
-        this.fs.getDefaultReplication());
+        FSUtils.getDefaultReplication(this.fs, this.dir));
     this.lowReplicationRollLimit = conf.getInt(
         "hbase.regionserver.hlog.lowreplication.rolllimit", 5);
     this.enabled = conf.getBoolean("hbase.regionserver.hlog.enabled", true);
@@ -453,33 +453,6 @@ public class HLog implements Syncable {
     }
     coprocessorHost = new WALCoprocessorHost(this, conf);
   }
-  
-  // use reflection to search for getDefaultBlockSize(Path f)
-  // if the method doesn't exist, fall back to using getDefaultBlockSize()
-  private long getDefaultBlockSize() throws IOException {
-    Method m = null;
-    Class<? extends FileSystem> cls = this.fs.getClass();
-    try {
-      m = cls.getMethod("getDefaultBlockSize",
-          new Class<?>[] { Path.class });
-    } catch (NoSuchMethodException e) {
-      LOG.info("FileSystem doesn't support getDefaultBlockSize");
-    } catch (SecurityException e) {
-      LOG.info("Doesn't have access to getDefaultBlockSize on "
-          + "FileSystems", e);
-      m = null; // could happen on setAccessible()
-    }
-    if (null == m) {
-      return this.fs.getDefaultBlockSize();
-    } else {
-      try {
-        Object ret = m.invoke(this.fs, this.dir);
-        return ((Long)ret).longValue();
-      } catch (Exception e) {
-        throw new IOException(e);
-      }
-    }
-  }
 
   /**
    * Find the 'getNumCurrentReplicas' on the passed <code>os</code> stream.
diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogWriter.java b/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogWriter.java
index fbe1ce5..0c09c83 100644
--- a/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogWriter.java
+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogWriter.java
@@ -34,6 +34,7 @@ import org.apache.hadoop.fs.FSDataOutputStream;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hbase.HConstants;
+import org.apache.hadoop.hbase.util.FSUtils;
 import org.apache.hadoop.io.SequenceFile;
 import org.apache.hadoop.io.Text;
 import org.apache.hadoop.io.SequenceFile.CompressionType;
@@ -161,9 +162,9 @@ public class SequenceFileLogWriter implements HLog.Writer {
             Integer.valueOf(fs.getConf().getInt("io.file.buffer.size", 4096)),
             Short.valueOf((short)
               conf.getInt("hbase.regionserver.hlog.replication",
-              fs.getDefaultReplication())),
+              FSUtils.getDefaultReplication(fs, path))),
             Long.valueOf(conf.getLong("hbase.regionserver.hlog.blocksize",
-                fs.getDefaultBlockSize())),
+                FSUtils.getDefaultBlockSize(fs, path))),
             Boolean.valueOf(false) /*createParent*/,
             SequenceFile.CompressionType.NONE, new DefaultCodec(),
             createMetadata(conf, compress)
@@ -182,9 +183,9 @@ public class SequenceFileLogWriter implements HLog.Writer {
         HLog.getKeyClass(conf), WALEdit.class,
         fs.getConf().getInt("io.file.buffer.size", 4096),
         (short) conf.getInt("hbase.regionserver.hlog.replication",
-          fs.getDefaultReplication()),
+          FSUtils.getDefaultReplication(fs, path)),
         conf.getLong("hbase.regionserver.hlog.blocksize",
-          fs.getDefaultBlockSize()),
+          FSUtils.getDefaultBlockSize(fs, path)),
         SequenceFile.CompressionType.NONE,
         new DefaultCodec(),
         null,
diff --git a/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java b/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java
index 259fa93..1b7c33d 100644
--- a/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java
+++ b/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java
@@ -376,6 +376,87 @@ public abstract class FSUtils {
     setVersion(fs, rootdir, HConstants.FILE_SYSTEM_VERSION, wait, retries);
   }
 
+  /**
+   * Return the number of bytes that large input files should be optimally
+   * be split into to minimize i/o time.
+   *
+   * use reflection to search for getDefaultBlockSize(Path f)
+   * if the method doesn't exist, fall back to using getDefaultBlockSize()
+   *
+   * @param fs filesystem object
+   * @return the default block size for the path's filesystem
+   * @throws IOException e
+   */
+  public static long getDefaultBlockSize(final FileSystem fs, final Path path) throws IOException {
+    Method m = null;
+    Class<? extends FileSystem> cls = fs.getClass();
+    try {
+      m = cls.getMethod("getDefaultBlockSize", new Class<?>[] { Path.class });
+    } catch (NoSuchMethodException e) {
+      LOG.info("FileSystem doesn't support getDefaultBlockSize");
+    } catch (SecurityException e) {
+      LOG.info("Doesn't have access to getDefaultBlockSize on FileSystems", e);
+      m = null; // could happen on setAccessible()
+    }
+    if (m == null) {
+      return fs.getDefaultBlockSize();
+    } else {
+      try {
+        Object ret = m.invoke(fs, path);
+        return ((Long)ret).longValue();
+      } catch (Exception e) {
+        throw new IOException(e);
+      }
+    }
+  }
+
+  /*
+   * Get the default replication.
+   *
+   * use reflection to search for getDefaultReplication(Path f)
+   * if the method doesn't exist, fall back to using getDefaultReplication()
+   *
+   * @param fs filesystem object
+   * @param f path of file
+   * @return default replication for the path's filesystem
+   * @throws IOException e
+   */
+  public static short getDefaultReplication(final FileSystem fs, final Path path) throws IOException {
+    Method m = null;
+    Class<? extends FileSystem> cls = fs.getClass();
+    try {
+      m = cls.getMethod("getDefaultReplication", new Class<?>[] { Path.class });
+    } catch (NoSuchMethodException e) {
+      LOG.info("FileSystem doesn't support getDefaultReplication");
+    } catch (SecurityException e) {
+      LOG.info("Doesn't have access to getDefaultReplication on FileSystems", e);
+      m = null; // could happen on setAccessible()
+    }
+    if (m == null) {
+      return fs.getDefaultReplication();
+    } else {
+      try {
+        Object ret = m.invoke(fs, path);
+        return ((Number)ret).shortValue();
+      } catch (Exception e) {
+        throw new IOException(e);
+      }
+    }
+  }
+
+  /**
+   * Returns the default buffer size to use during writes.
+   *
+   * The size of the buffer should probably be a multiple of hardware
+   * page size (4096 on Intel x86), and it determines how much data is
+   * buffered during read and write operations.
+   *
+   * @param fs filesystem object
+   * @return default buffer size to use during writes
+   */
+  public static int getDefaultBufferSize(final FileSystem fs) {
+    return fs.getConf().getInt("io.file.buffer.size", 4096);
+  }
 
   /**
    * Sets version of file system
-- 
1.7.0.4

