From 806d2ea5898a3e92b5c7926a5f62e629c2633a12 Mon Sep 17 00:00:00 2001
From: Todd Lipcon <todd@cloudera.com>
Date: Fri, 2 Dec 2011 15:10:50 -0800
Subject: [PATCH 1058/1357] MR1: Build changes

---
 build.xml                |  821 ++++++++++++----------------------------------
 ivy.xml                  |  333 +++++--------------
 ivy/libraries.properties |   53 ++--
 src/contrib/build.xml    |    2 -
 4 files changed, 324 insertions(+), 885 deletions(-)

diff --git a/build.xml b/build.xml
index e9851f9..e559dc1 100644
--- a/build.xml
+++ b/build.xml
@@ -72,9 +72,7 @@
   <property name="streaming.final.name" value="${name}-streaming-${version}"/>
 
   <property name="src.dir" value="${basedir}/src"/>  	
-  <property name="core.src.dir" value="${src.dir}/core"/>
   <property name="mapred.src.dir" value="${src.dir}/mapred"/> 
-  <property name="hdfs.src.dir" value="${src.dir}/hdfs"/>
   <property name="native.src.dir" value="${basedir}/src/native"/>
   <property name="examples.dir" value="${basedir}/src/examples"/>
   <property name="anttasks.dir" value="${basedir}/src/ant"/>
@@ -129,7 +127,6 @@
   <property name="test.src.dir" value="${basedir}/src/test"/>
   <property name="test.lib.dir" value="${basedir}/src/test/lib"/>
   <property name="test.build.dir" value="${build.dir}/test"/>
-  <property name="test.generated.dir" value="${test.build.dir}/src"/>
   <property name="test.build.data" value="${test.build.dir}/data"/>
   <property name="test.cache.data" value="${test.build.dir}/cache"/>
   <property name="test.debug.data" value="${test.build.dir}/debug"/>
@@ -140,7 +137,6 @@
   <property name="test.build.extraconf" value="${test.build.dir}/extraconf"/>
   <property name="test.build.javadoc" value="${test.build.dir}/docs/api"/>
   <property name="test.build.javadoc.dev" value="${test.build.dir}/docs/dev-api"/>
-  <property name="test.build.webapps" value="${build.dir}/test/test-webapps"/>
   <property name="test.include" value="Test*"/>
   <property name="test.classpath.id" value="test.classpath"/>
   <property name="test.output" value="no"/>
@@ -266,8 +262,7 @@
     location="${build.dir}/contrib/streaming/${streaming.final.name}.jar"/>
    
   <!--this is the naming policy for artifacts we want pulled down-->
-  <property name="ivy.artifact.retrieve.pattern" 
-    value="${ant.project.name}/[conf]/[artifact]-[revision].[ext]"/>
+  <property name="ivy.artifact.retrieve.pattern" value="${ant.project.name}/[conf]/[artifact]-[revision](-[classifier]).[ext]"/>
 
   <!--this is how artifacts that get built are named-->
   <property name="ivy.publish.pattern" value="hadoop-[revision]-core.[ext]"/>
@@ -280,9 +275,17 @@
 
   <property name="clover.jar" location="${clover.home}/lib/clover.jar"/>
   <available property="clover.present" file="${clover.jar}" />
-
-  <!-- Use environment -->
-  <property environment="env" />
+	
+  <!-- Eclipse properties -->
+  <property name="build.dir.eclipse" value="build/eclipse"/>
+  <property name="build.dir.eclipse-main-classes" value="${build.dir.eclipse}/classes-main"/>
+  <property name="build.dir.eclipse-test-classes" value="${build.dir.eclipse}/classes-test"/>
+  <property name="build.dir.eclipse-test-generated-classes" value="${build.dir.eclipse}/classes-test-generated"/>
+  <property name="build.dir.eclipse-example-classes" value="${build.dir.eclipse}/classes-example"/>
+  <property name="build.dir.eclipse-tools-classes" value="${build.dir.eclipse}/classes-tools"/>
+  <property name="build.dir.eclipse-contrib-classes" value="${build.dir.eclipse}/classes-contrib"/>
+  <property name="build.dir.eclipse-test-resources" value="${build.dir.eclipse}/test-resources/"/>
+  <property name="build.dir.eclipse-test-resources-webapps" value="${build.dir.eclipse}/test-resources/webapps"/>
 
   <!-- check if clover reports should be generated -->
   <condition property="clover.enabled">
@@ -296,40 +299,41 @@
      <equals arg1="${repo}" arg2="staging"/>
   </condition>
 
-  <!-- Indicate is Snappy native library should be bundled with Hadoop or not -->
-  <property name="bundle.snappy" value="false"/>
-
-  <!-- Snappy native library location -->
-  <property name="snappy.prefix" value="/usr/local"/>
-  <property name="snappy.lib" value="${snappy.prefix}/lib"/>
-  <property name="snappy.include" value="${snappy.prefix}/include"/>
-
   <!-- the normal classpath -->
   <path id="classpath">
     <pathelement location="${build.classes}"/>
+    <path refid="src.lib.classpath"/>
+    <pathelement location="${conf.dir}"/>
+  </path>
+
+  <path id="src.lib.classpath">
     <fileset dir="${lib.dir}">
       <include name="**/*.jar" />
       <exclude name="**/excluded/" />
     </fileset>
-    <pathelement location="${conf.dir}"/>
     <path refid="ivy-common.classpath"/>
   </path>
 
+  <path id="test.lib.classpath">
+    <fileset dir="${test.lib.dir}">
+      <include name="**/*.jar"/>
+      <exclude name="**/excluded/"/>
+    </fileset>
+  </path>
+
   <!-- the unit test classpath: uses test.src.dir for configuration -->
   <path id="test.classpath">
     <pathelement location="${test.build.extraconf}"/>
     <pathelement location="${test.build.classes}" />
     <pathelement location="${test.src.dir}"/>
-    <pathelement location="${test.build.dir}"/>
     <pathelement location="${build.dir}"/>
     <pathelement location="${build.examples}"/>
     <pathelement location="${build.tools}"/>
     <pathelement path="${clover.jar}"/>
-    <fileset dir="${test.lib.dir}">
-      <include name="**/*.jar"/>
-      <exclude name="**/excluded/"/>
-    </fileset>
+    <path refid="test.lib.classpath"/>
+    <pathelement location="${hadoop-core.jar}"/>
     <path refid="classpath"/>
+    <path refid="ivy-test.classpath" />
   </path>
 
   <!-- the cluster test classpath: uses conf.dir for configuration -->
@@ -380,9 +384,6 @@
     <mkdir dir="${build.src}"/>
     <mkdir dir="${build.webapps}/task/WEB-INF"/>
     <mkdir dir="${build.webapps}/job/WEB-INF"/>
-    <mkdir dir="${build.webapps}/hdfs/WEB-INF"/>
-    <mkdir dir="${build.webapps}/datanode/WEB-INF"/>
-    <mkdir dir="${build.webapps}/secondary/WEB-INF"/>
     <mkdir dir="${build.examples}"/>
     <mkdir dir="${build.anttasks}"/>
     <mkdir dir="${build.dir}/c++"/>
@@ -416,67 +417,18 @@
       <mapper type="glob" from="*.template" to="*"/>
     </copy>
 
+    <exec executable="sh">
+       <arg line="src/saveVersion.sh ${version} ${build.dir}"/>
+    </exec>
   </target>
 
-  <import file="${test.src.dir}/aop/build/aop.xml"/>
-
   <!-- ====================================================== -->
   <!-- Compile the Java files                                 -->
   <!-- ====================================================== -->
-  <target name="record-parser" depends="init" if="javacc.home">
-      <javacc
-          target="${core.src.dir}/org/apache/hadoop/record/compiler/generated/rcc.jj"
-          outputdirectory="${core.src.dir}/org/apache/hadoop/record/compiler/generated"
-          javacchome="${javacc.home}" />
-  </target>
-  
-  <target name="compile-rcc-compiler" depends="init, record-parser">
-    <javac 
-        encoding="${build.encoding}" 
-        srcdir="${core.src.dir}"
-        includes="org/apache/hadoop/record/compiler/**/*.java"
-        destdir="${build.classes}"
-        debug="${javac.debug}"
-        optimize="${javac.optimize}"
-        target="${javac.version}"
-        source="${javac.version}"
-        deprecation="${javac.deprecation}">
-        <compilerarg line="${javac.args}"/>
-        <classpath refid="classpath"/>
-    </javac>
-    
-    <taskdef name="recordcc" classname="org.apache.hadoop.record.compiler.ant.RccTask">
-      <classpath refid="classpath" />
+  <target name="compile-mapred-classes" depends="init">
+    <taskdef classname="org.apache.jasper.JspC" name="jsp-compile" >
+       <classpath refid="classpath"/>
     </taskdef>
-  </target>
-  
-  <target name="compile-core-classes" depends="init, compile-rcc-compiler">
-     <taskdef classname="org.apache.jasper.JspC" name="jsp-compile" >
-        <classpath refid="test.classpath"/>
-     </taskdef>
-    <!-- Compile Java files (excluding JSPs) checking warnings -->
-    <javac 
-     encoding="${build.encoding}" 
-     srcdir="${core.src.dir}"	
-     includes="org/apache/hadoop/**/*.java"
-     destdir="${build.classes}"
-     debug="${javac.debug}"
-     optimize="${javac.optimize}"
-     target="${javac.version}"
-     source="${javac.version}"
-     deprecation="${javac.deprecation}">
-      <compilerarg line="${javac.args} ${javac.args.warnings}" />
-      <classpath refid="classpath"/>
-    </javac>
-
-    <copy todir="${build.classes}">
-      <fileset dir="${core.src.dir}" includes="**/*.properties"/>
-      <fileset dir="${core.src.dir}" includes="core-default.xml"/>
-    </copy>
-     
-  </target>
-
-  <target name="compile-mapred-classes" depends="compile-core-classes,compile-hdfs-classes">
     <jsp-compile
      uriroot="${src.webapps}/task"
      outputdir="${build.src}"
@@ -484,8 +436,12 @@
      webxml="${build.webapps}/task/WEB-INF/web.xml">
     </jsp-compile>
 
+    <copy todir="${build.webapps}/job">
+      <fileset dir="${src.webapps}/job" includes="**/*.jsp"/>
+    </copy>
+     
     <jsp-compile
-     uriroot="${src.webapps}/job"
+     uriroot="${build.webapps}/job"
      outputdir="${build.src}"
      package="org.apache.hadoop.mapred"
      webxml="${build.webapps}/job/WEB-INF/web.xml">
@@ -512,57 +468,6 @@
     </copy>
   </target>
 
-  <target name="compile-hdfs-classes" depends="compile-core-classes">
-    <jsp-compile
-     uriroot="${src.webapps}/hdfs"
-     outputdir="${build.src}"
-     package="org.apache.hadoop.hdfs.server.namenode"
-     webxml="${build.webapps}/hdfs/WEB-INF/web.xml">
-    </jsp-compile>
-
-    <jsp-compile
-     uriroot="${src.webapps}/datanode"
-     outputdir="${build.src}"
-     package="org.apache.hadoop.hdfs.server.datanode"
-     webxml="${build.webapps}/datanode/WEB-INF/web.xml">
-    </jsp-compile>
-
-    <jsp-compile
-     uriroot="${src.webapps}/secondary"
-     outputdir="${build.src}"
-     package="org.apache.hadoop.hdfs.server.namenode"
-     webxml="${build.webapps}/secondary/WEB-INF/web.xml">
-    </jsp-compile>
-    
-    <!-- generate package-info annotation file. This has to be done here
-      so that the timestamp of package-info.java is newer than the timestamp
-      of the output directory -->
-    <exec executable="sh">
-       <arg line="src/saveVersion.sh ${version} ${build.dir}"/>
-       <env key="HADOOP_REVISION" value="${cloudera.hash}" />
-    </exec>
-	
-    <!-- Compile Java files (excluding JSPs) checking warnings -->
-    <javac 
-     encoding="${build.encoding}" 
-     srcdir="${hdfs.src.dir};${build.src}" 
-     includes="org/apache/hadoop/**/*.java"
-     destdir="${build.classes}"
-     debug="${javac.debug}"
-     optimize="${javac.optimize}"
-     target="${javac.version}"
-     source="${javac.version}"
-     deprecation="${javac.deprecation}">
-      <compilerarg line="${javac.args} ${javac.args.warnings}" />
-      <classpath refid="classpath"/>
-    </javac>   
-
-    <copy todir="${build.classes}">
-     <fileset dir="${hdfs.src.dir}" includes="**/*.properties"/>
-     <fileset dir="${hdfs.src.dir}" includes="hdfs-default.xml"/>
-    </copy>
-  </target>
-
   <target name="compile-tools" depends="init">
     <javac 
      encoding="${build.encoding}" 
@@ -586,113 +491,14 @@
     </copy>
   </target>
 
-  <target name="compile-native">
-    <antcall target="compile-core-native">
-      <param name="compile.native" value="true"/>
-    </antcall> 
-  </target>
-
-  <target name="check-native-configure" if="compile.native">
-    <condition property="need.native.configure">
-       <not> <available file="${native.src.dir}/configure"/> </not>
-    </condition>
-  </target>
-
-  <target name="create-native-configure" depends="check-native-configure" if="need.native.configure">
-    <mkdir dir="${native.src.dir}/config"/>
-    <mkdir dir="${native.src.dir}/m4"/>
-    <exec executable="autoreconf" dir="${native.src.dir}"
-          searchpath="yes" failonerror="yes">
-       <arg value="-i"/>
-       <arg value="-f"/>
-    </exec>
-  </target>
-
-  <target name="check-native-makefile" if="compile.native">
-    <condition property="need.native.makefile">
-       <not> <available file="${native.src.dir}/Makefile"/> </not>
-    </condition>
-  </target>
-
-  <target name="create-native-makefile" depends="check-native-makefile" if="need.native.makefile">
-    <antcall target="create-native-configure"/>
-    <mkdir dir="${build.native}"/>
-
-    <exec dir="${build.native}" executable="sh" failonerror="true">
-          <env key="OS_NAME" value="${os.name}"/>
-          <env key="OS_ARCH" value="${os.arch}"/>
-          <env key="JVM_DATA_MODEL" value="${sun.arch.data.model}"/>
-          <env key="HADOOP_NATIVE_SRCDIR" value="${native.src.dir}"/>
-          <arg line="${native.src.dir}/configure CPPFLAGS=-I${snappy.include} LDFLAGS=-L${snappy.lib}"/>
-    </exec>
-  </target>
-
-  <target name="compile-core-native" depends="compile-core-classes,create-native-makefile"
-          if="compile.native">
-  	
-    <mkdir dir="${build.native}/lib"/>
-    <mkdir dir="${build.native}/src/org/apache/hadoop/io/compress/zlib"/>
-    <mkdir dir="${build.native}/src/org/apache/hadoop/io/compress/snappy"/>
-    <mkdir dir="${build.native}/src/org/apache/hadoop/io/nativeio"/>
-    <mkdir dir="${build.native}/src/org/apache/hadoop/security"/>
-
-    <javah
-      classpath="${build.classes}"
-      destdir="${build.native}/src/org/apache/hadoop/io/compress/snappy"
-      force="yes"
-      verbose="yes"
-      >
-      <class name="org.apache.hadoop.io.compress.snappy.SnappyCompressor"/>
-      <class name="org.apache.hadoop.io.compress.snappy.SnappyDecompressor"/>
-    </javah>
-
-    <javah
-  	  classpath="${build.classes}"
-  	  destdir="${build.native}/src/org/apache/hadoop/io/compress/zlib"
-      force="yes"
-  	  verbose="yes"
-  	  >
-  	  <class name="org.apache.hadoop.io.compress.zlib.ZlibCompressor" />
-      <class name="org.apache.hadoop.io.compress.zlib.ZlibDecompressor" />
-  	</javah>
-  	<javah
-  	  classpath="${build.classes}"
-  	  destdir="${build.native}/src/org/apache/hadoop/io/nativeio"
-      force="yes"
-  	  verbose="yes"
-  	  >
-  	  <class name="org.apache.hadoop.io.nativeio.NativeIO" />
-  	</javah>
-  	<javah
-  	  classpath="${build.classes}"
-  	  destdir="${build.native}/src/org/apache/hadoop/security"
-      force="yes"
-  	  verbose="yes"
-  	  >
-          <class name="org.apache.hadoop.security.JniBasedUnixGroupsMapping" />
-          <class name="org.apache.hadoop.security.JniBasedUnixGroupsNetgroupMapping" />
-  	</javah>
-
-    <exec dir="${build.native}" executable="${make.cmd}" failonerror="true">
-      <env key="OS_NAME" value="${os.name}"/>
-      <env key="OS_ARCH" value="${os.arch}"/>
-  	  <env key="JVM_DATA_MODEL" value="${sun.arch.data.model}"/>
-  	  <env key="HADOOP_NATIVE_SRCDIR" value="${native.src.dir}"/>
-    </exec>
-
-	<exec dir="${build.native}" executable="sh" failonerror="true">
-	  <arg line="${build.native}/libtool --mode=install cp ${build.native}/lib/libhadoop.la ${build.native}/lib"/>
-    </exec>
-
-  </target>
 
   <target name="compile-core"
-          depends="clover,compile-core-classes,compile-mapred-classes,
-  	compile-hdfs-classes,compile-core-native,compile-c++" 
+          depends="clover,compile-mapred-classes,
+  	compile-c++" 
   	description="Compile core only">
   </target>
 
-  <target name="compile-contrib" depends="compile-core,tools-jar,compile-c++-libhdfs">
+  <target name="compile-contrib" depends="compile-core,tools-jar">
      <subant target="compile">
         <property name="version" value="${version}"/>
         <fileset file="${contrib.dir}/build.xml"/>
@@ -786,42 +592,22 @@
   </target>
 
   <!-- ================================================================== -->
-  <!-- Make the Hadoop metrics jar. (for use outside Hadoop)              -->
+  <!-- Make the Hadoop metrics plugin dev/sdk jar. (for use outside Hadoop)              -->
   <!-- ================================================================== -->
   <!--                                                                    -->
   <!-- ================================================================== -->
-  <target name="metrics.jar" depends="compile-core" description="Make the Hadoop metrics jar. (for use outside Hadoop)">
-    <jar jarfile="${build.dir}/hadoop-metrics-${version}.jar"
+  <target name="metrics.jar" depends="compile-core" description="Make the Hadoop metrics plugin dev/sdk jar. (for use outside Hadoop)">
+    <jar jarfile="${build.dir}/hadoop-metrics-dev-${version}.jar"
          basedir="${build.classes}">
-      <include name="**/metrics/**" />
-      <exclude name="**/package.html" />
+      <include name="**/metrics2/*.class" />
+      <include name="**/metrics2/util/*.class" />
     </jar>
   </target>
 
-  <target name="generate-test-records" depends="compile-rcc-compiler">
-    <recordcc destdir="${test.generated.dir}">
-      <fileset dir="${test.src.dir}"
-	         includes="**/*.jr" />
-    </recordcc>
-  </target>
-  
   <!-- ================================================================== -->
   <!-- Compile test code                                                  --> 
   <!-- ================================================================== -->
-  <target name="compile-core-test" depends="compile-examples, compile-tools, generate-test-records">
-    <javac 
-     encoding="${build.encoding}" 
-     srcdir="${test.generated.dir}"
-     includes="org/apache/hadoop/**/*.java"
-     destdir="${test.build.classes}"
-     debug="${javac.debug}"
-     optimize="${javac.optimize}"
-     target="${javac.version}"
-     source="${javac.version}"
-     deprecation="${javac.deprecation}">
-      <compilerarg line="${javac.args}" />
-      <classpath refid="test.classpath"/>
-    </javac>
+  <target name="compile-core-test" depends="compile-examples, compile-tools, ivy-retrieve-test">
     <javac 
      encoding="${build.encoding}" 
      srcdir="${test.src.dir}"
@@ -881,15 +667,6 @@
     <copy file="${test.src.dir}/org/apache/hadoop/mapred/test.tar" todir="${test.cache.data}"/>
     <copy file="${test.src.dir}/org/apache/hadoop/mapred/test.tgz" todir="${test.cache.data}"/>
     <copy file="${test.src.dir}/org/apache/hadoop/mapred/test.tar.gz" todir="${test.cache.data}"/>
-    <copy file="${test.src.dir}/org/apache/hadoop/hdfs/hadoop-14-dfs-dir.tgz" todir="${test.cache.data}"/>
-    <copy file="${test.src.dir}/org/apache/hadoop/hdfs/hadoop-dfs-dir.txt" todir="${test.cache.data}"/>
-    <copy file="${test.src.dir}/org/apache/hadoop/cli/testConf.xml" todir="${test.cache.data}"/>
-    <copy file="${test.src.dir}/org/apache/hadoop/cli/clitest_data/data15bytes" todir="${test.cache.data}"/>
-    <copy file="${test.src.dir}/org/apache/hadoop/cli/clitest_data/data30bytes" todir="${test.cache.data}"/>
-    <copy file="${test.src.dir}/org/apache/hadoop/cli/clitest_data/data60bytes" todir="${test.cache.data}"/>
-    <copy file="${test.src.dir}/org/apache/hadoop/cli/clitest_data/data120bytes" todir="${test.cache.data}"/>
-    <copy file="${test.src.dir}/org/apache/hadoop/hdfs/tools/offlineImageViewer/fsimageV18" todir="${test.cache.data}"/>
-    <copy file="${test.src.dir}/org/apache/hadoop/hdfs/tools/offlineImageViewer/fsimageV19" todir="${test.cache.data}"/>
   </target>
 
   <!-- ================================================================== -->
@@ -897,7 +674,7 @@
   <!-- ================================================================== -->
   <!--                                                                    -->
   <!-- ================================================================== -->
-  <target name="jar-test" depends="compile-core-test" description="Make hadoop-test.jar">
+  <target name="jar-test" depends="jar,compile-core-test" description="Make hadoop-test.jar">
     <jar jarfile="${build.dir}/${test.final.name}.jar"
          basedir="${test.build.classes}">
          <manifest>
@@ -912,48 +689,6 @@
     </jar>
   </target>
 
-  <!-- ================================================================== -->
-  <!-- Fault injection customization section.
-       These targets ought to be copied over to other projects and modified
-       as needed -->
-  <!-- ================================================================== -->
-  <target name="-classes-compilation" depends="compile-core-classes,
-      compile-hdfs-classes, compile-mapred-classes, compile-core-test"/>
-  <target name="run-test-core-fault-inject" depends="injectfaults"
-	  description="Run full set of the unit tests with fault injection">
-    <macro-run-tests-fault-inject target.name="test-core"
-      testcasesonly="false"/>
-  </target>
-
-  <target name="jar-test-fault-inject" depends="injectfaults"
-    description="Make hadoop-test-fi.jar">
-    <macro-jar-test-fault-inject
-      target.name="jar-test"
-      jar.final.name="test.final.name"
-      jar.final.value="${test.final.name}-fi" />
-  </target>
-
-  <target name="jar-fault-inject" depends="injectfaults"
-    description="Make hadoop-fi.jar">
-    <macro-jar-fault-inject
-      target.name="jar"
-      build.dir="${build-fi.dir}"
-      jar.final.name="final.name"
-      jar.final.value="${final.name}-fi" />
-  </target>
-
-  <!--This target is not included into the the top level list of target
-  for it serves a special "regression" testing purpose of non-FI tests in
-  FI environment -->
-  <target name="run-fault-inject-with-testcaseonly" depends="injectfaults">
-    <fail unless="testcase">Can't run this target without -Dtestcase setting!
-    </fail>
-    <macro-run-tests-fault-inject target.name="test-core"
-      testcasesonly="true"/>
-  </target>
-  <!-- ================================================================== -->
-  <!-- End of Fault injection customization section                       -->
-  <!-- ================================================================== -->
 
   <condition property="tests.notestcase">
     <and>
@@ -963,47 +698,24 @@
       </not>
     </and>
   </condition>
-  <condition property="tests.notestcase.fi">
-    <and>
-      <not>
-        <isset property="testcase" />
-      </not>
-      <istrue value="${test.fault.inject}" />
-    </and>
-  </condition>
   <condition property="tests.testcase">
     <and>
       <isfalse value="${test.fault.inject}" />
       <isset property="testcase" />
     </and>
   </condition>
-  <condition property="tests.testcase.fi">
-    <and>
-      <istrue value="${test.fault.inject}" />
-      <isset property="testcase" />
-    </and>
-  </condition>
   <!-- ================================================================== -->
-  <!-- Run unit tests                                                     --> 
+  <!-- Define exclude lists for different kinds of testing -->
   <!-- ================================================================== -->
-  <target name="test-core" depends="jar-test" description="Run core unit tests">
-    <macro-test-runner classpath="${test.classpath.id}"
-                       test.dir="${test.build.dir}"
-                       fileset.dir="${test.src.dir}"
-                       test.file="${test.all.tests.file}"
-                       test.krb5.conf="java.security.krb5.conf"
-                       test.krb5.conf.filename="${test.src.dir}/krb5.conf" />
-  </target>   
-  
-  <target name="test-commit" depends="jar-test" description="Run core unit tests">
-    <macro-test-runner classpath="${test.classpath.id}"
-                       test.dir="${test.build.dir}"
-                       fileset.dir="${test.src.dir}"
-                       test.file="${test.commit.tests.file}"
-                       test.krb5.conf="java.security.krb5.conf"
-                       test.krb5.conf.filename="${test.src.dir}/krb5.conf" />
-  </target>   
+  <patternset id="empty.exclude.list.id" />
+    <patternset id="commit.smoke.exclude.list.id">
+    <excludesfile name="${test.commit.tests.file}"/>
+    <excludesfile name="${test.smoke.tests.file}"/>
+  </patternset>
 
+  <!-- ================================================================== -->
+  <!-- Run unit tests                                                     --> 
+  <!-- ================================================================== -->
   <macrodef name="macro-test-runner">
     <attribute name="test.file" />
     <attribute name="classpath" />
@@ -1012,6 +724,7 @@
     <attribute name="hadoop.conf.dir.deployed" default="" />
     <attribute name="test.krb5.conf" default="" />
     <attribute name="test.krb5.conf.filename" default="" />
+    <attribute name="exclude.list.id" default="empty.exclude.list.id" />
     <sequential>
       <delete dir="@{test.dir}/data" />
       <mkdir dir="@{test.dir}/data" />
@@ -1021,9 +734,6 @@
             todir="@{test.dir}/extraconf" />
       <copy file="${test.src.dir}/fi-site.xml"
             todir="@{test.dir}/extraconf" />
-      <copy todir="${test.build.webapps}">
-        <fileset dir="${test.src.dir}/test-webapps" includes="**/*" />
-      </copy>
       <junit showoutput="${test.output}"
              printsummary="${test.junit.printsummary}"
              haltonfailure="${test.junit.haltonfailure}"
@@ -1071,44 +781,81 @@
         <syspropertyset id="FaultProbabilityProperties">
           <propertyref regex="fi.*" />
         </syspropertyset>
-        <syspropertyset id="TestCLIProperties">
-          <propertyref regex="test.cli.*" />
-          <propertyref name="fs.default.name" />
-          <propertyref name="mapred.job.tracker" />
-        </syspropertyset>
         <formatter type="${test.junit.output.format}" />
         <batchtest todir="@{test.dir}" if="tests.notestcase">
           <fileset dir="@{fileset.dir}"
                    excludes="**/${test.exclude}.java aop/** system/**">
             <patternset>
               <includesfile name="@{test.file}"/>
-              <excludesfile name="${test.exclude.file}" />
             </patternset>
+            <patternset refid="@{exclude.list.id}"/>
           </fileset>
         </batchtest>
-        <batchtest todir="${test.build.dir}" if="tests.notestcase.fi">
-          <fileset dir="${test.src.dir}/aop"
-                   includes="**/${test.include}.java"
-                   excludes="**/${test.exclude}.java"
-                   excludesfile="${test.exclude.file}" />
-        </batchtest>
         <batchtest todir="@{test.dir}" if="tests.testcase">
           <fileset dir="@{fileset.dir}"
             includes="**/${testcase}.java" excludes="aop/** system/**"/>
         </batchtest>
-        <batchtest todir="${test.build.dir}" if="tests.testcase.fi">
-          <fileset dir="${test.src.dir}/aop" includes="**/${testcase}.java" />
-        </batchtest>
-        <!--The following batch is for very special occasions only when
-                a non-FI tests are needed to be executed against FI-environment -->
-        <batchtest todir="${test.build.dir}" if="tests.testcaseonly">
-          <fileset dir="${test.src.dir}" includes="**/${testcase}.java" />
-        </batchtest>
       </junit>
       <antcall target="checkfailure"/>
     </sequential>
   </macrodef>
 
+  <target name="test-core" depends="test-commit, test-smoke,
+    test-core-excluding-commit-and-smoke,
+    test-core-all-withtestcaseonly, jar-test"
+    description="Run core unit tests">
+  </target>
+
+  <target name="test-core-all-withtestcaseonly" depends="jar-test" if="testcase">
+    <macro-test-runner test.file="${test.all.tests.file}"
+                       classpath="${test.classpath.id}"
+                       test.dir="${test.build.dir}"
+                       fileset.dir="${test.src.dir}"
+                       test.krb5.conf="java.security.krb5.conf"
+                       test.krb5.conf.filename="${test.src.dir}/krb5.conf"
+                       >
+    </macro-test-runner>
+  </target>
+
+  <target name="test-core-excluding-commit-and-smoke" depends="jar-test"
+    unless="testcase">
+    <macro-test-runner test.file="${test.all.tests.file}"
+                       classpath="${test.classpath.id}"
+                       test.dir="${test.build.dir}"
+                       fileset.dir="${test.src.dir}"
+                       test.krb5.conf="java.security.krb5.conf"
+                       test.krb5.conf.filename="${test.src.dir}/krb5.conf"
+                       exclude.list.id="commit.smoke.exclude.list.id"
+                       >
+    </macro-test-runner>
+  </target>   
+
+  <target name="test-commit" depends="jar-test" 
+    description="Run approx 10-minute set of unit tests prior to commiting"
+    unless="testcase">
+    <macro-test-runner test.file="${test.commit.tests.file}"
+                       classpath="${test.classpath.id}"
+                       test.dir="${test.build.dir}"
+                       fileset.dir="${test.src.dir}"
+                       test.krb5.conf="java.security.krb5.conf"
+                       test.krb5.conf.filename="${test.src.dir}/krb5.conf"
+                       >
+    </macro-test-runner>
+  </target>
+
+  <target name="test-smoke" depends="jar-test"
+    description="Run approx 30-minute set of functional tests prior to
+      guarantee that the build is not DOA" unless="testcase">
+    <macro-test-runner test.file="${test.smoke.tests.file}"
+                       classpath="${test.classpath.id}"
+                       test.dir="${test.build.dir}"
+                       fileset.dir="${test.src.dir}"
+                       test.krb5.conf="java.security.krb5.conf"
+                       test.krb5.conf.filename="${test.src.dir}/krb5.conf"
+                       >
+    </macro-test-runner>
+  </target>
+
   <target name="checkfailure" if="tests.failed">
     <touch file="${test.build.dir}/testsfailed"/>
     <fail unless="continueOnFailure">Tests failed!</fail>
@@ -1122,14 +869,14 @@
     </subant> 
   </target>
 	  
-  <target name="test" description="Run core, contrib tests">
+  <target name="test" description="Run core, contrib, fault injection tests">
     <delete file="${test.build.dir}/testsfailed"/>
     <property name="continueOnFailure" value="true"/>
     <antcall target="test-core"/>
     <antcall target="test-contrib"/>
     <available file="${test.build.dir}/testsfailed" property="testsfailed"/>
     <fail if="testsfailed">Tests failed!</fail>
-  </target>  
+  </target>
 
   <!-- Run all unit tests, not just Test*, and use non-test configuration. -->
   <target name="test-cluster" description="Run all unit tests, not just Test*, and use non-test configuration.">
@@ -1154,9 +901,7 @@
   	
   	<checkstyle config="${test.src.dir}/checkstyle.xml"
   		failOnViolation="false">
-      <fileset dir="${core.src.dir}" includes="**/*.java" excludes="**/generated/**"/>
       <fileset dir="${mapred.src.dir}" includes="**/*.java" excludes="**/generated/**"/>
-      <fileset dir="${hdfs.src.dir}" includes="**/*.java" excludes="**/generated/**"/>  		
       <formatter type="xml" toFile="${test.build.dir}/checkstyle-errors.xml"/>
   	</checkstyle>
   	
@@ -1193,9 +938,7 @@
           <include name="**/*.jar"/>
         </fileset>
       </auxClasspath>
-      <sourcePath path="${core.src.dir}"/>
       <sourcePath path="${mapred.src.dir}"/>
-      <sourcePath path="${hdfs.src.dir}"/>
       <sourcePath path="${examples.dir}" />
       <sourcePath path="${tools.src}" />
       <sourcePath path="${basedir}/src/contrib/streaming/src/java" />
@@ -1228,10 +971,6 @@
       <fileset dir="${docs.src}/build/site/" />
     </copy>
     <copy file="${docs.src}/releasenotes.html" todir="${build.docs}"/>
-    <style basedir="${core.src.dir}" destdir="${build.docs}"
-           includes="core-default.xml" style="conf/configuration.xsl"/>
-    <style basedir="${hdfs.src.dir}" destdir="${build.docs}"
-           includes="hdfs-default.xml" style="conf/configuration.xsl"/>
     <style basedir="${mapred.src.dir}" destdir="${build.docs}"
            includes="mapred-default.xml" style="conf/configuration.xsl"/>
     <antcall target="changes-to-html"/>
@@ -1244,7 +983,6 @@
   <target name="javadoc-dev" description="Generate javadoc for hadoop developers">
     <mkdir dir="${build.javadoc.dev}"/>
     <javadoc
-      overview="${core.src.dir}/overview.html"
       packagenames="org.apache.hadoop.*"
       destdir="${build.javadoc.dev}"
       author="true"
@@ -1255,9 +993,7 @@
       bottom="Copyright &amp;copy; ${year} The Apache Software Foundation"
       maxmemory="${javadoc.maxmemory}"
       >
-        <packageset dir="${core.src.dir}"/>
         <packageset dir="${mapred.src.dir}"/>
-        <packageset dir="${hdfs.src.dir}"/>        	
     	<packageset dir="${examples.dir}"/>
 
     	<packageset dir="src/contrib/streaming/src/java"/>
@@ -1298,7 +1034,6 @@
        unless="javadoc.is.uptodate">
     <mkdir dir="${build.javadoc}"/>
     <javadoc
-      overview="${core.src.dir}/overview.html"
       packagenames="org.apache.hadoop.*"
       destdir="${build.javadoc}"
       author="true"
@@ -1309,7 +1044,6 @@
       bottom="Copyright &amp;copy; ${year} The Apache Software Foundation"
       maxmemory="${javadoc.maxmemory}"
       >
-        <packageset dir="${core.src.dir}"/>
         <packageset dir="${mapred.src.dir}"/>
     	<packageset dir="${examples.dir}"/>
 
@@ -1366,7 +1100,7 @@
 
   <target name="api-report" depends="ivy-retrieve-jdiff,api-xml">
     <mkdir dir="${jdiff.build.dir}"/>
-    <javadoc sourcepath="src/core,src/hdfs,src,mapred,src/tools"
+    <javadoc sourcepath="src,mapred,src/tools"
              destdir="${jdiff.build.dir}"
 	     sourceFiles="${jdiff.home}/Null.java"
 	     maxmemory="${javadoc.maxmemory}">
@@ -1477,12 +1211,7 @@
     </macro_tar>
   </target>
 
-  <target name="package-native" depends="compile-core-native, compile-c++, compile-c++-examples, compile-c++-libhdfs">
-    <mkdir dir="${dist.dir}"/>
-    <copy-native-package />
-  </target>
-
-  <target name="bin-package" depends="create-native-configure, create-libhdfs-configure, create-c++-configure, compile, jar, examples, tools-jar, jar-test, ant-tasks, package-librecordio" 
+  <target name="bin-package" depends="compile, jar, examples, tools-jar, jar-test, ant-tasks" 
 		description="assembles artifacts for binary target">
 
     <mkdir dir="${dist.dir}"/>
@@ -1574,31 +1303,6 @@
 
   </target>
 
-  <target name="binary-system" depends="bin-package, jar-system, jar-test-system"
-     description="make system test package for deployment">
-    <copy todir="${system-test-build-dir}/${final.name}">
-      <fileset dir="${dist.dir}">
-      </fileset>
-    </copy>
-    <copy todir="${system-test-build-dir}/${final.name}" 
-      file="${system-test-build-dir}/${core.final.name}.jar" overwrite="true"/>
-    <copy todir="${system-test-build-dir}/${final.name}"
-      file="${system-test-build-dir}/${test.final.name}.jar" overwrite="true"/>
-    <macro_tar 
-      param.destfile="${system-test-build-dir}/${final.name}-bin.tar.gz">
-        <param.listofitems>
-          <tarfileset dir="${system-test-build-dir}" mode="664">
-            <exclude name="${final.name}/bin/*" />
-            <exclude name="${final.name}/src/**" />
-            <exclude name="${final.name}/docs/**" />
-            <include name="${final.name}/**" />
-          </tarfileset>
-          <tarfileset dir="${build.dir}" mode="755">
-            <include name="${final.name}/bin/*" />
-          </tarfileset>
-        </param.listofitems>
-      </macro_tar>
-  </target>
   
   <target name="binary" depends="bin-package" description="Make tarball without source and documentation">
     <macro_tar param.destfile="${build.dir}/${final.name}-bin.tar.gz">
@@ -1608,7 +1312,6 @@
           <exclude name="${final.name}/src/**" />
           <exclude name="${final.name}/docs/**" />
           <include name="${final.name}/**" />
-          <include name="${final.name}/eclipse.templates/**" />
         </tarfileset>
         <tarfileset dir="${build.dir}" mode="755">
           <include name="${final.name}/bin/*" />
@@ -1631,7 +1334,7 @@
   <!-- ================================================================== -->
   <!-- Clean.  Delete the build files, and their directories              -->
   <!-- ================================================================== -->
-  <target name="clean" depends="clean-contrib, clean-sign, clean-fi" description="Clean.  Delete the build files, and their directories">
+  <target name="clean" depends="clean-contrib, clean-sign" description="Clean.  Delete the build files, and their directories">
     <delete dir="${build.dir}"/>
     <delete dir="${docs.src}/build"/>
     <delete file="${basedir}/build.properties" />
@@ -1658,138 +1361,9 @@
         <fileset file="src/contrib/build.xml"/>
      </subant>  	
   </target>
+	
 
-
- <target name="test-c++-libhdfs" depends="compile-c++-libhdfs, compile-core" if="islibhdfs">
-    <delete dir="${test.libhdfs.dir}"/>
-    <mkdir dir="${test.libhdfs.dir}"/>
-    <mkdir dir="${test.libhdfs.dir}/logs"/>
-    <mkdir dir="${test.libhdfs.dir}/hdfs/name"/>
-
-    <exec dir="${build.c++.libhdfs}" executable="${make.cmd}" failonerror="true">
-        <env key="OS_NAME" value="${os.name}"/>
-        <env key="OS_ARCH" value="${os.arch}"/>
-        <env key="JVM_ARCH" value="${jvm.arch}"/>
-        <env key="LIBHDFS_BUILD_DIR" value="${build.c++.libhdfs}"/>
-        <env key="HADOOP_HOME" value="${basedir}"/>
-        <env key="HADOOP_CONF_DIR" value="${test.libhdfs.conf.dir}"/>
-        <env key="HADOOP_LOG_DIR" value="${test.libhdfs.dir}/logs"/>
-        <env key="LIBHDFS_SRC_DIR" value="${c++.libhdfs.src}"/>
-        <env key="LIBHDFS_INSTALL_DIR" value="${install.c++}/lib"/>  
-        <env key="LIB_DIR" value="${common.ivy.lib.dir}"/>
-		<arg value="test"/>
-    </exec>
-  </target>
-
-<!-- ================================================================== -->
-<!-- librecordio targets.                                               -->
-<!-- ================================================================== -->		
-
-  <target name="compile-librecordio" depends="init" if="librecordio" >
-     <mkdir dir="${build.librecordio}"/>
-     <exec dir="${librecordio.src}" executable="${make.cmd}" failonerror="true">
-        <env key="XERCESCROOT" value="${xercescroot}"/>
-        <env key="LIBRECORDIO_BUILD_DIR" value="${build.librecordio}"/>
-     </exec>
-  </target>
-  	
-  <target name="test-librecordio" depends="compile-librecordio, compile-core" if="librecordio">
-    <delete dir="${librecordio.test.dir}"/>
-    <mkdir dir="${librecordio.test.dir}"/>
-    <exec dir="${librecordio.src}/test" executable="${make.cmd}" failonerror="true">
-        <env key="HADOOP_HOME" value="${basedir}"/>
-	<env key="XERCESCROOT" value="${xercescroot}"/>
-        <env key="LIBRECORDIO_BUILD_DIR" value="${build.librecordio}"/> 	
-        <env key="LIBRECORDIO_TEST_DIR" value="${librecordio.test.dir}"/>
-      		<arg value="all"/>		
-    </exec>
-  </target>
-
-  <target name="package-librecordio" depends="compile-librecordio" if="librecordio">
-    <mkdir dir="${dist.dir}/librecordio"/> 
-    <copy todir="${dist.dir}/librecordio">
-       <fileset dir="${build.librecordio}" casesensitive="yes" followsymlinks="false">
-          <exclude name="**/tests/**"/>
-          <exclude name="*.so"/> 
-          <exclude name="*.o"/>
-       </fileset>
-    </copy>
-    <chmod perm="ugo+x" type="file">
-       <fileset dir="${dist.dir}/librecordio"/>
-    </chmod>
-  </target>
-
-  <target name="check-libhdfs-configure" depends="init,check-c++-libhdfs" if="islibhdfs">
-    <condition property="need.libhdfs.configure">
-       <not> <available file="${c++.libhdfs.src}/configure"/> </not>
-    </condition>
-  </target>
-
-
-  <target name="check-c++-configure" depends="init" if="compile.c++">
-    <condition property="need.c++.utils.configure">
-       <not> <available file="${c++.utils.src}/configure"/> </not>
-    </condition>
-    <condition property="need.c++.pipes.configure">
-       <not> <available file="${c++.pipes.src}/configure"/> </not>
-    </condition>
-    <condition property="need.c++.examples.pipes.configure">
-       <not> <available file="${c++.examples.pipes.src}/configure"/> </not>
-    </condition>
-    <condition property="need.c++.task-controller.configure">
-       <not> <available file="${c++.task-controller.src}/configure"/> </not>
-    </condition>
-  </target>
-
-
-  <target name="create-libhdfs-configure" depends="check-libhdfs-configure" if="need.libhdfs.configure">
-    <mkdir dir="${c++.libhdfs.src}/config"/>
-    <exec executable="autoreconf" dir="${c++.libhdfs.src}"
-          searchpath="yes" failonerror="yes">
-       <arg value="-if"/>
-    </exec>
-  </target>
-
- 
-  <target name="create-c++-utils-configure" depends="check-c++-configure"
-                                            if="need.c++.utils.configure">
-    <exec executable="autoreconf" dir="${c++.utils.src}" searchpath="yes" 
-          failonerror="yes">
-       <arg value="-if"/>
-    </exec>
-  </target>
-  
-  <target name="create-c++-pipes-configure" depends="check-c++-configure"
-                                            if="need.c++.pipes.configure">
-    <exec executable="autoreconf" dir="${c++.pipes.src}" searchpath="yes" 
-          failonerror="yes">
-       <arg value="-if"/>
-    </exec>
-  </target>
-
-
-  <target name="create-c++-examples-pipes-configure" depends="check-c++-configure"
-                                            if="need.c++.examples.pipes.configure">
-    <exec executable="autoreconf" dir="${c++.examples.pipes.src}" searchpath="yes" 
-          failonerror="yes">
-       <arg value="-if"/>
-    </exec>
-  </target>
-
-  <target name="create-c++-task-controller-configure" depends="check-c++-configure"
-                                                      if="need.c++.task-controller.configure">
-    <exec executable="autoreconf" dir="${c++.task-controller.src}" 
-          searchpath="yes" failonerror="yes">
-       <arg value="-if"/>
-    </exec>
-  </target>
-
-  <target name="create-c++-configure" depends="create-c++-utils-configure,
-                                               create-c++-pipes-configure,
-                                               create-c++-examples-pipes-configure,
-                                               create-c++-task-controller-configure"
-                                      if="compile.c++">
-  </target>
+   
 
   <target name="check-c++-makefiles" depends="init" if="compile.c++">
     <condition property="need.c++.utils.makefile">
@@ -1803,37 +1377,9 @@
     </condition>
   </target>
 
-  <target name="check-c++-libhdfs">
-    <condition property="islibhdfs">
-      <and>
-        <isset property="compile.c++"/>
-        <isset property="libhdfs"/>
-      </and>
-    </condition>
-  </target>
-
-  <target name="check-libhdfs-makefile" depends="init,check-c++-libhdfs" if="islibhdfs">
-    <condition property="need.libhdfs.makefile">
-       <not> <available file="${build.c++.libhdfs}/Makefile"/> </not>
-    </condition>
-  </target>
-
-  <target name="create-libhdfs-makefile" depends="check-libhdfs-makefile" 
-                                           if="need.libhdfs.makefile">
-    <antcall target="create-libhdfs-configure"/>
-    <mkdir dir="${build.c++.libhdfs}"/>
-    <exec executable="${c++.libhdfs.src}/configure" dir="${build.c++.libhdfs}"
-          failonerror="yes">
-      <env key="ac_cv_func_malloc_0_nonnull" value="yes"/>
-      <env key="JVM_ARCH" value="${jvm.arch}"/>
-      <arg value="--prefix=${install.c++}"/>
-      <env key="base_dir" value="${basedir}"/>
-    </exec>
-  </target>
 
   <target name="create-c++-utils-makefile" depends="check-c++-makefiles" 
                                            if="need.c++.utils.makefile">
-    <antcall target="create-c++-utils-configure"/>
     <mkdir dir="${build.c++.utils}"/>
     <chmod file="${c++.utils.src}/configure" perm="ugo+x"/>
     <exec executable="${c++.utils.src}/configure" dir="${build.c++.utils}"
@@ -1852,7 +1398,6 @@
 
   <target name="create-c++-pipes-makefile" depends="check-c++-makefiles" 
                                            if="need.c++.pipes.makefile">
-    <antcall target="create-c++-pipes-configure"/>
     <mkdir dir="${build.c++.pipes}"/>
     <chmod file="${c++.pipes.src}/configure" perm="ugo+x"/>
     <exec executable="${c++.pipes.src}/configure" dir="${build.c++.pipes}"
@@ -1871,12 +1416,11 @@
   </target>
 
   <target name="compile-c++" 
-          depends="compile-c++-pipes, jsvc"/>
+          depends="compile-c++-pipes"/>
 
   <target name="create-c++-examples-pipes-makefile" 
           depends="check-c++-makefiles" 
           if="need.c++.examples.pipes.makefile">
-    <antcall target="create-c++-examples-pipes-configure"/>
     <mkdir dir="${build.c++.examples.pipes}"/>
     <chmod file="${c++.examples.pipes.src}/configure" perm="ugo+x"/>
     <exec executable="${c++.examples.pipes.src}/configure" 
@@ -1900,19 +1444,6 @@
   <target name="compile-c++-examples" 
           depends="compile-c++-examples-pipes"/>
 
-  <target name="compile-c++-libhdfs" depends="create-libhdfs-makefile" if="islibhdfs">
-    <exec executable="${make.cmd}" dir="${build.c++.libhdfs}" searchpath="yes"
-          failonerror="yes">
-      <env key="ac_cv_func_malloc_0_nonnull" value="yes"/>
-      <env key="JVM_ARCH" value="${jvm.arch}"/>
-      <arg value="install"/>
-    </exec>
-    <!-- Create a build platform-agnostic link to c++ libs -->
-    <symlink overwrite="true" link="${build.dir}/c++/lib" resource="${install.c++}/lib"/>
-  </target>
-
-
-
   <target name="compile-ant-tasks" depends="compile-core">
     <javac
         encoding="${build.encoding}"
@@ -1945,7 +1476,8 @@
    <taskdef resource="cloverlib.xml" classpath="${clover.jar}"/>
    <mkdir dir="${clover.db.dir}"/>
    <clover-setup initString="${clover.db.dir}/hadoop_coverage.db">
-     <fileset dir="src" includes="core/**/* tools/**/* hdfs/**/* mapred/**/*"/>
+     <fileset dir="${src.dir}" includes="tools/**/* mapred/**/*"/>
+     <testsources dir="${test.src.dir}" />
    </clover-setup>
 </target>
 
@@ -2021,23 +1553,99 @@
     <arg value="${basedir}"/>
     <arg value="${trigger.url}"/>
     <arg value="${jira.passwd}"/>
+    <arg value="${java5.home}"/>
   </exec>
 </target>
 	
-  <target name="eclipse-files" depends="init"
-          description="Generate files for Eclipse">
-    <pathconvert property="eclipse.project">
-      <path path="${basedir}"/>
-      <regexpmapper from="^.*/([^/]+)$$" to="\1" handledirsep="yes"/>
-    </pathconvert>
+  <condition property="ant-eclipse.jar.exists">
+    <available file="${build.dir}/lib/ant-eclipse-1.0-jvm1.2.jar"/>
+  </condition>
+
+  <target name="ant-eclipse-download" unless="ant-eclipse.jar.exists"
+          description="Downloads the ant-eclipse binary.">
+    <get src="http://downloads.sourceforge.net/project/ant-eclipse/ant-eclipse/1.0/ant-eclipse-1.0.bin.tar.bz2"
+         dest="${build.dir}/ant-eclipse-1.0.bin.tar.bz2" usetimestamp="false" />
+
+    <untar src="${build.dir}/ant-eclipse-1.0.bin.tar.bz2"
+           dest="${build.dir}" compression="bzip2">
+      <patternset>
+        <include name="lib/ant-eclipse-1.0-jvm1.2.jar"/>
+      </patternset>
+    </untar>
+    <delete file="${build.dir}/ant-eclipse-1.0.bin.tar.bz2" />
+  </target>
+
+  <target name="eclipse" 
+          depends="init,ant-eclipse-download,ivy-retrieve-common,ivy-retrieve-test,compile-core-test"
+          description="Create eclipse project files">
+	     <pathconvert property="eclipse.project">
+	       <path path="${basedir}"/>
+	       <regexpmapper from="^.*/([^/]+)$$" to="\1" handledirsep="yes"/>
+	     </pathconvert>
+    <taskdef name="eclipse"
+             classname="prantl.ant.eclipse.EclipseTask"
+             classpath="${build.dir}/lib/ant-eclipse-1.0-jvm1.2.jar" />
+    <eclipse updatealways="true">
+      <project name="${eclipse.project}" />
+      <classpath>
+        <source path="${src.dir}/mapred"
+                output="${build.dir.eclipse-main-classes}" />
+        <source path="${test.src.dir}/"
+                output="${build.dir.eclipse-test-classes}" 
+                excluding="aop/|mapred/|system/|bin/|ddl/|lib/|tools/"/>
+        <source path="${test.src.dir}/aop"
+                output="${build.dir.eclipse-test-classes}" />
+        <source path="${tools.src}"
+                output="${build.dir.eclipse-tools-classes}" />
+        <source path="${examples.dir}"
+                output="${build.dir.eclipse-example-classes}" />
+        <source path="${contrib.dir}/data_join/src/examples"
+                output="${build.dir.eclipse-contrib-classes}/data_join/examples" />
+        <source path="${contrib.dir}/data_join/src/test"
+                output="${build.dir.eclipse-contrib-classes}/data_join/test" />
+        <source path="${contrib.dir}/data_join/src/java"
+                output="${build.dir.eclipse-contrib-classes}/data_join/java" />
+        <source path="${contrib.dir}/streaming/src/java"
+                output="${build.dir.eclipse-contrib-classes}/streaming/main" />
+        <source path="${contrib.dir}/streaming/src/test"
+                output="${build.dir.eclipse-contrib-classes}/streaming/test" 
+                excluding="system/"/>
+        <source path="${contrib.dir}/vaidya/src/java"
+                output="${build.dir.eclipse-contrib-classes}/vaidya/main" />
+        <source path="${contrib.dir}/fairscheduler/src/java"
+                output="${build.dir.eclipse-contrib-classes}/fairscheduler/main" />
+        <source path="${contrib.dir}/fairscheduler/src/test"
+                output="${build.dir.eclipse-contrib-classes}/fairscheduler/test" />
+        <source path="${contrib.dir}/gridmix/src/java"
+                output="${build.dir.eclipse-contrib-classes}/gridmix/main" />
+        <source path="${contrib.dir}/gridmix/src/test"
+                output="${build.dir.eclipse-contrib-classes}/gridmix/test"
+                excluding="system/"/>
+       <source path="${contrib.dir}/capacity-scheduler/src/java"
+                output="${build.dir.eclipse-contrib-classes}/capacity-scheduler/main" />
+        <source path="${contrib.dir}/capacity-scheduler/src/test"
+                output="${build.dir.eclipse-contrib-classes}/capacity-scheduler/test" />
+        <output path="${build.dir.eclipse-main-classes}" />
+        <library pathref="src.lib.classpath" exported="false" />
+        <library pathref="test.lib.classpath" exported="false" />
+        <variable path="ANT_HOME/lib/ant.jar" exported="false" />
+        <library path="${conf.dir}" exported="false" />
+        <library path="${build.dir.eclipse-test-resources}" exported="false" />
+      </classpath>
+    </eclipse>
     <copy todir="." overwrite="true">
       <fileset dir=".eclipse.templates">
-      	<exclude name="**/README.txt"/>
+        <exclude name="**/README.txt"/>
       </fileset>
       <filterset>
         <filter token="PROJECT" value="${eclipse.project}"/>
       </filterset>
     </copy>
+    <!-- copy all of the jsp and static files -->
+    <copy todir="${build.dir.eclipse-test-resources-webapps}">
+      <fileset dir="${build.webapps}">
+      </fileset>
+    </copy>
   </target>
 
   <target name="ivy-init-dirs">
@@ -2146,7 +1754,7 @@
     description="Retrieve Ivy-managed artifacts for the test configurations">
     <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
       pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"/>
-    <ivy:cachepath pathid="test.classpath" conf="test"/>
+    <ivy:cachepath pathid="ivy-test.classpath" conf="test"/>
   </target>
 
   <target name="ivy-retrieve-common" depends="ivy-resolve-common"
@@ -2359,15 +1967,4 @@
 
   <!-- end of task-controller targets -->
 
-  <!-- jsvc targets -->
-  <target name="jsvc" if="compile.c++">
-    <subant target="jsvc">
-      <property name="c++.jsvc.src" value="${c++.jsvc.src}" />
-      <property name="build.c++.jsvc" value="${build.c++}/jsvc" />
-      <property name="jsvc.install.dir" value="${dist.dir}/sbin/${build.platform}" /> 
-      <property name="jsvc.arch" value="${jvm.arch}" />
-      <fileset file="${c++.jsvc.src}/build.xml"/>
-    </subant>
-  </target>
-
 </project>
diff --git a/ivy.xml b/ivy.xml
index 37eb23e..234ca55 100644
--- a/ivy.xml
+++ b/ivy.xml
@@ -1,5 +1,3 @@
-<?xml version="1.0" ?>
-
 <!--
    Licensed to the Apache Software Foundation (ASF) under one or more
    contributor license agreements.  See the NOTICE file distributed with
@@ -17,8 +15,8 @@
    limitations under the License.
 -->
 
-<ivy-module version="1.0">
-  <info organisation="org.apache.hadoop" module="${ant.project.name}">
+<ivy-module version="1.0" xmlns:m="http://ant.apache.org/ivy/maven">
+  <info organisation="org.apache.hadoop" module="${ant.project.name}" revision="${version}">
     <license name="Apache 2.0"/>
     <ivyauthor name="Apache Hadoop Team" url="http://hadoop.apache.org"/>
     <description>
@@ -29,46 +27,27 @@
     <!--these match the Maven configurations-->
     <conf name="default" extends="master,runtime"/>
     <conf name="master" description="contains the artifact but no dependencies"/>
-    <conf name="runtime" description="runtime but not the artifact"
-      extends="client,server,s3-server,kfs"/>
-
-    <conf name="mandatory" description="contains the critical  dependencies"
-      extends="commons-logging,log4j"/>
+    <conf name="compile" description="contains the artifact but no dependencies"/>
+    <conf name="runtime" description="runtime but not the artifact"/>
 
     <!--
     These public configurations contain the core dependencies for running hadoop client or server.
     The server is effectively a superset of the client.
     -->
-    <conf name="client" description="client-side dependencies"
-      extends="mandatory,httpclient"/>
-    <conf name="server" description="server-side dependencies"
-      extends="client"/>
-    <conf name="s3-client" description="dependencies for working with S3/EC2 infrastructure"
-      extends="client"/>
-    <conf name="s3-server" description="dependencies for running on S3/EC2 infrastructure"
-      extends="s3-client,server"/>
-    <conf name="kfs" description="dependencies for KFS file system support"/>
-    <conf name="ftp" description="dependencies for workign with FTP filesytems"
-              extends="mandatory"/>
-   <conf name="jetty" description="Jetty provides the in-VM HTTP daemon" extends="commons-logging"/>
-
     <!--Private configurations. -->
 
-    <conf name="common" visibility="private" extends="runtime,mandatory,httpclient,ftp,jetty"
-		      description="common artifacts"/>
-    <conf name="javadoc" visibility="private" description="artiracts required while performing doc generation"
-      extends="common,mandatory,jetty,lucene"/>
-    <!--Testing pulls in everything-->
-    <conf name="test" extends="common,default,s3-server,kfs" visibility="private"
-      description="the classpath needed to run tests"/>
-    <conf name="releaseaudit" visibility="private"
-	description="Artifacts required for releaseaudit target"/>
+    <conf name="common" visibility="private" extends="compile" description="common artifacts"/>
+    <conf name="mapred" visibility="private" extends="compile,runtime" description="Mapred dependent artifacts"/>
+    <conf name="javadoc" visibility="private" description="artiracts required while performing doc generation" extends="common"/>
+    <conf name="test" extends="master" visibility="private" description="the classpath needed to run tests"/>
+    <conf name="package" extends="master" description="the classpath needed for packaging"/>
+    <conf name="system" extends="test" visibility="private" description="the classpath needed to run system tests"/>
+
+    <conf name="test-hdfswithmr" extends="test" visibility="private" description="the classpath needed to run tests"/>
+
+    <conf name="releaseaudit" visibility="private" description="Artifacts required for releaseaudit target"/>
      
-    <conf name="commons-logging" visibility="private"/>
-    <conf name="httpclient" visibility="private" extends="commons-logging"/>
-    <conf name="log4j" visibility="private"/>
-    <conf name="lucene" visibility="private"/>
-    <conf name="jdiff" visibility="private" extends="log4j,s3-client,jetty,server"/>
+    <conf name="jdiff" visibility="private" extends="common"/>
     <conf name="checkstyle" visibility="private"/>
 
   </configurations>
@@ -79,220 +58,76 @@
   </publications>
   <dependencies>
 
- <!--used client side-->
-    <dependency org="commons-cli"
-      name="commons-cli"
-      rev="${commons-cli.version}"
-      conf="client->default"/>
-
-    <dependency org="checkstyle"
-      name="checkstyle"
-      rev="${checkstyle.version}"
-      conf="checkstyle->default"/>
-    <dependency org="jdiff"
-      name="jdiff"
-      rev="${jdiff.version}"
-      conf="jdiff->default"/>
-    <dependency org="xerces"
-      name="xerces"
-      rev="${xerces.version}"
-      conf="jdiff->default">
-    </dependency>
-
-    <dependency org="xmlenc"
-      name="xmlenc"
-      rev="${xmlenc.version}"
-      conf="server->default"/>
-
-    <dependency org="org.apache.hadoop.thirdparty.guava"
-      name="guava"
-      rev="r09-jarjar"
-      conf="client->default" />
-
-    <!--Configuration: httpclient-->
-
-    <!--
-    commons-httpclient asks for too many files.
-    All it needs is commons-codec and commons-logging JARs
-    -->
-    <dependency org="commons-httpclient"
-      name="commons-httpclient"
-      rev="${commons-httpclient.version}"
-      conf="httpclient->master">
-    </dependency>
-
-    <dependency org="commons-codec"
-      name="commons-codec"
-      rev="${commons-codec.version}"
-      conf="httpclient->default"/>
-
-    <dependency org="commons-net"
-      name="commons-net"
-      rev="${commons-net.version}"
-      conf="ftp->default"/>
-
-    <!--Configuration: Jetty -->
-
-<!-- <dependency org="javax.servlet"
-      name="servlet-api"
-      rev="${servlet-api.version}"
-      conf="jetty->master"/>   -->
-    <dependency org="org.mortbay.jetty"
-      name="jetty"
-      rev="${jetty.version}"
-      conf="jetty->master"/>
-    <dependency org="org.mortbay.jetty"
-      name="jetty-util"
-      rev="${jetty-util.version}"
-      conf="jetty->master"/>
-
-    <dependency org="tomcat"
-      name="jasper-runtime"
-      rev="${jasper.version}"
-      conf="jetty->master"/>
-    <dependency org="tomcat"
-      name="jasper-compiler"
-      rev="${jasper.version}"
-      conf="jetty->master"/>
-<!-- this is resolved locally from the lib folder 
-   <dependency org="tomcat"
-      name="jsp-api"
-      rev="${jsp-api.version}"
-      conf="jetty->master"/> -->
-    <dependency org="commons-el"
-      name="commons-el"
-      rev="${commons-el.version}"
-      conf="jetty->master"/>
-
-    <!--Configuration: secure datanode -->
-    <dependency org="commons-daemon" 
-      name="commons-daemon" 
-      rev="${commons-daemon.version}"
-      conf="server->default" /> 
-
-    <dependency org="com.jcraft"
-      name="jsch"
-      rev="${jsch.version}"
-      conf="common->master">
-    </dependency>
-    
-    <!--Configuration: commons-logging -->
-
-    <!--it is essential that only the master JAR of commons logging
-    is pulled in, as its dependencies are usually a mess, including things
-    like out of date servlet APIs, bits of Avalon, etc.
-    -->
-    <dependency org="commons-logging"
-      name="commons-logging"
-      rev="${commons-logging.version}"
-      conf="commons-logging->master"/>
-
-
-    <!--Configuration: commons-logging -->
-
-    <!--log4J is not optional until commons-logging.properties is stripped out of the JAR -->
-    <dependency org="log4j"
-      name="log4j"
-      rev="${log4j.version}"
-      conf="log4j->master"/>
-
-    <!--Configuration: s3-client -->
-    <!--there are two jets3t projects in the repository; this one goes up to 0.6 and
-    is assumed to be the live one-->
-    <dependency org="net.java.dev.jets3t"
-      name="jets3t"
-      rev="${jets3t.version}"
-      conf="s3-client->master"/>
-    <dependency org="commons-net"
-      name="commons-net"
-      rev="${commons-net.version}"
-      conf="s3-client->master"/> 
-    <dependency org="org.mortbay.jetty"
-      name="servlet-api-2.5"
-      rev="${servlet-api-2.5.version}"
-      conf="s3-client->master"/>
-
-    <!--Configuration: kfs -->
-
-    <!-- This is not in the repository
-  <dependency org="org.kosmix"
-    name="kfs"
-    rev="${kfs.version}"
-    conf="kfs->default"/>-->
-
-    <!--Configuration: test -->
-
-    <!--artifacts needed for testing -->
-    <dependency org="junit"
-      name="junit"
-      rev="${junit.version}"
-      conf="common->default"/>
-    <dependency org="com.google.code.p.arat"
-      name="rat-lib"
-      rev="${rats-lib.version}"
-      conf="releaseaudit->default"/>
-    <dependency org="commons-lang"
-      name="commons-lang"
-      rev="${commons-lang.version}"
-      conf="common->default"/>
-    <dependency org="commons-collections"
-      name="commons-collections"
-      rev="${commons-collections.version}"
-      conf="releaseaudit->default"/>
-<!--<dependency org="hsqldb"
-      name="hsqldb"
-      rev="${hsqldb.version}"
-      conf="common->default"/>
-    <dependency org="lucene"
-      name="lucene"
-      rev="${lucene.version}"
-      conf="javadoc->default"/> --> 
-    <dependency org="org.apache.lucene"
-      name="lucene-core"
-      rev="${lucene-core.version}"
-      conf="javadoc->default"/> 
-    <dependency org="commons-logging"
-      name="commons-logging-api"
-      rev="${commons-logging-api.version}"
-      conf="common->default"/>
-    <dependency org="org.slf4j"
-      name="slf4j-api"
-      rev="${slf4j-api.version}"
-      conf="common->master"/>
-    <dependency org="org.eclipse.jdt"
-      name="core"
-      rev="${core.version}"
-      conf="common->master"/>
-    <dependency org="oro"
-      name="oro"
-      rev="${oro.version}"
-      conf="common->default"/>
-    <dependency org="org.slf4j"
-      name="slf4j-log4j12"
-      rev="${slf4j-log4j12.version}"
-      conf="common->master">
-    </dependency>
-    <dependency org="org.mockito"
-      name="mockito-all"
-      rev="${mockito-all.version}"
-      conf="common->master"/>
-    <dependency org="org.mortbay.jetty"
-      name="jetty-servlet-tester"
-      rev="${jetty.version}"
-      conf="common->default" />
-    <dependency org="org.codehaus.jackson"
-      name="jackson-mapper-asl"
-      rev="${jackson.version}"
-      conf="common->default"/>
-    <dependency org="org.aspectj"
-      name="aspectjrt"
-      rev="${aspectj.version}"
-      conf="common->default">
+   <dependency org="org.apache.hadoop" name="hadoop-annotations" rev="${hadoop-common.version}" conf="compile->default"/>
+   <dependency org="org.apache.hadoop" name="hadoop-common" 
+               rev="${hadoop-common.version}" conf="compile->default">
+     <artifact name="hadoop-common" ext="jar" />
+     <artifact name="hadoop-common" type="tests" ext="jar" m:classifier="tests" />
+   </dependency>
+   <dependency org="org.apache.hadoop" name="hadoop-hdfs" 
+               rev="${hadoop-hdfs.version}" conf="compile->default"/> 
+   <dependency org="org.apache.hadoop" name="hadoop-common-instrumented"
+               rev="${hadoop-common.version}" conf="system->default"/>
+   <dependency org="org.apache.hadoop" name="hadoop-hdfs-instrumented"
+               rev="${hadoop-hdfs.version}" conf="system->default"/>
+   <dependency org="commons-logging" name="commons-logging" 
+               rev="${commons-logging.version}" conf="compile->master"/>
+   <dependency org="org.slf4j" name="slf4j-api" rev="${slf4j-api.version}" 
+               conf="compile->master"/>
+   <dependency org="org.slf4j" name="slf4j-log4j12" 
+               rev="${slf4j-log4j12.version}" conf="mapred->master"/>
+   <dependency org="org.apache.hadoop" name="hadoop-hdfs" 
+               rev="${hadoop-hdfs.version}" conf="test->default">
+     <artifact name="hadoop-hdfs" type="tests" ext="jar" m:classifier="tests"/>
+   </dependency>
+   <dependency org="org.apache.hadoop" name="hadoop-common" 
+               rev="${hadoop-common.version}" conf="test->default">
+     <artifact name="hadoop-common" type="tests" ext="jar" m:classifier="tests" />
+   </dependency>
+   <dependency org="log4j" name="log4j" rev="${log4j.version}" 
+               conf="compile->master"/>
+
+   <dependency org="org.apache.rat" name="apache-rat-tasks" 
+               rev="${rats-lib.version}" conf="releaseaudit->default"/>
+   <dependency org="commons-lang" name="commons-lang" 
+               rev="${commons-lang.version}" conf="releaseaudit->default"/>
+   <dependency org="commons-collections" name="commons-collections" 
+               rev="${commons-collections.version}" 
+               conf="releaseaudit->default"/>
+
+   <dependency org="org.apache.lucene" name="lucene-core" 
+               rev="${lucene-core.version}" conf="javadoc->default"/>
+   <dependency org="org.apache.avro" name="avro-compiler" rev="${avro.version}" 
+               conf="compile->master">
+      <exclude module="ant"/>
+      <exclude module="jetty"/>
+      <exclude module="slf4j-simple"/>
     </dependency>
-    <dependency org="org.aspectj"
-      name="aspectjtools"
-      rev="${aspectj.version}"
-      conf="common->default">
+   <dependency org="org.apache.avro" name="avro" rev="${avro.version}" 
+               conf="compile->default">
+      <exclude module="ant"/>
+      <exclude module="jetty"/>
+      <exclude module="slf4j-simple"/>
     </dependency>
+   <dependency org="junit" name="junit" rev="${junit.version}"
+               conf="test->default"/>
+   <dependency org="org.mockito" name="mockito-all" rev="${mockito-all.version}" 
+               conf="test->default"/>
+   <dependency org="org.vafer" name="jdeb" rev="${jdeb.version}" conf="package->master"/>
+   <dependency org="org.mortbay.jetty" name="jetty-servlet-tester" rev="${jetty.version}"
+               conf="test->default"/>
+   <!-- dependency addition for the fault injection -->
+   <dependency org="org.aspectj" name="aspectjrt" rev="${aspectj.version}"
+               conf="compile->default"/>
+   <dependency org="org.aspectj" name="aspectjtools" rev="${aspectj.version}"
+               conf="compile->default"/>
+
+   <!-- Exclusions for transitive dependencies pulled in by log4j -->
+   <exclude org="com.sun.jdmk"/>
+   <exclude org="com.sun.jmx"/>
+   <exclude org="javax.jms"/> 
+   <exclude org="javax.mail"/> 
+   <exclude org="org.apache.hadoop" module="avro"/> 
  </dependencies>
+  
 </ivy-module>
diff --git a/ivy/libraries.properties b/ivy/libraries.properties
index 0b3c715..8b4035d 100644
--- a/ivy/libraries.properties
+++ b/ivy/libraries.properties
@@ -14,22 +14,23 @@
 #It drives ivy and the generation of a maven POM
 
 #These are the versions of our dependencies (in alphabetical order)
-apacheant.version=1.7.0
 ant-task.version=2.0.10
 
+#Aspectj depedency for Fault injection
+#This property has to be updated synchronously with aop.xml
 aspectj.version=1.6.5
 
+avro.version=1.5.2
+paranamer.version=2.2
 checkstyle.version=4.2
 
-jsch.version=0.1.42
 commons-cli.version=1.2
 commons-codec.version=1.4
 commons-collections.version=3.1
-commons-daemon.version=1.0.1
 commons-httpclient.version=3.1
-commons-lang.version=2.4
-commons-logging.version=1.0.4
-commons-logging-api.version=1.0.4
+commons-lang.version=2.5
+commons-logging.version=1.1.1
+commons-logging-api.version=1.1
 commons-el.version=1.0
 commons-fileupload.version=1.2
 commons-io.version=1.4
@@ -37,41 +38,49 @@ commons-net.version=1.4.1
 core.version=3.1.1
 coreplugin.version=1.3.2
 
+ftplet-api.version=1.0.0
+ftpserver-core.version=1.0.0
+ftpserver-deprecated.version=1.0.0-M2
+
+hadoop-common.version=0.23.0-SNAPSHOT
+hadoop-hdfs.version=0.23.0-SNAPSHOT
+
 hsqldb.version=1.8.0.10
 
-#ivy.version=2.0.0-beta2
-ivy.version=2.0.0-rc2
+ivy.version=2.2.0
 
-jackson.version=1.5.2
 jasper.version=5.5.12
-#not able to figureout the version of jsp & jsp-api version to get it resolved throught ivy
-# but still declared here as we are going to have a local copy from the lib folder
+jdeb.version=0.8
 jsp.version=2.1
 jsp-api.version=5.5.12
-jets3t.version=0.6.1
-jetty.version=6.1.26.cloudera.1
-jetty-util.version=6.1.26.cloudera.1
-junit.version=4.5
+jets3t.version=0.7.1
+jetty.version=6.1.14
+jetty-util.version=6.1.14
+junit.version=4.8.1
 jdiff.version=1.0.9
-json.version=1.0
 
-kfs.version=0.1
+kfs.version=0.3
 
-log4j.version=1.2.15
+log4j.version=1.2.16
 lucene-core.version=2.3.1
 
-mockito-all.version=1.8.2
+mina-core.version=2.0.0-M5
+
+mockito-all.version=1.8.5
 
 oro.version=2.0.8
 
-rats-lib.version=0.5.1
+rats-lib.version=0.6
 
 servlet.version=4.0.6
 servlet-api-2.5.version=6.1.14
 servlet-api.version=2.5
-slf4j-api.version=1.4.3
-slf4j-log4j12.version=1.4.3
+slf4j-api.version=1.5.11
+slf4j-log4j12.version=1.5.11
 
 wagon-http.version=1.0-beta-2
 xmlenc.version=0.52
 xerces.version=1.4.4
+
+yarn.version=0.23.0-SNAPSHOT
+hadoop-mapreduce.version=0.23.0-SNAPSHOT
diff --git a/src/contrib/build.xml b/src/contrib/build.xml
index e41c132..99fbc9e 100644
--- a/src/contrib/build.xml
+++ b/src/contrib/build.xml
@@ -51,7 +51,6 @@
     <subant target="test">
       <property name="continueOnFailure" value="true"/>
       <fileset dir="." includes="fuse-dfs/build.xml"/>
-      <fileset dir="." includes="hdfsproxy/build.xml"/>
       <fileset dir="." includes="streaming/build.xml"/>
       <fileset dir="." includes="fairscheduler/build.xml"/>
       <fileset dir="." includes="capacity-scheduler/build.xml"/>
@@ -76,7 +75,6 @@
        <property name="hadoop.conf.dir" value="${hadoop.conf.dir}"/>
        <property name="hadoop.conf.dir.deployed"
            value="${hadoop.conf.dir.deployed}"/>
-       <fileset dir="." includes="hdfsproxy/build.xml"/>
        <fileset dir="." includes="streaming/build.xml"/>
        <fileset dir="." includes="fairscheduler/build.xml"/>
        <fileset dir="." includes="capacity-scheduler/build.xml"/>
-- 
1.7.0.4

