From 7f619ed9fce353788a5fd16eb627d77925ac9729 Mon Sep 17 00:00:00 2001
From: Tom White <tom@cloudera.com>
Date: Wed, 12 Sep 2012 14:40:17 +0100
Subject: [PATCH 1193/1357] MR1: HDFS-3910 (DFSTestUtil#waitReplication should timeout).

Reason: Improvement
Ref: CDH-7935
Author: Eli Collins and Tom White
(cherry picked from commit 7405ca726f8ccf360f1206d14c393be19c32fb18)
---
 .../apache/hadoop/mapred/TestFileInputFormat.java  |    3 +-
 .../hadoop/mapred/TestJobInProgressListener.java   |    2 +-
 .../hadoop/mapred/TestJobQueueInformation.java     |    2 +-
 .../hadoop/mapred/TestJobTrackerRestart.java       |   10 +++---
 .../TestJobTrackerRestartWithLostTracker.java      |    6 ++--
 .../org/apache/hadoop/mapred/TestLostTracker.java  |    6 ++--
 .../hadoop/mapred/TestMultipleLevelCaching.java    |    4 +-
 .../hadoop/mapred/TestRackAwareTaskPlacement.java  |    2 +-
 .../hadoop/mapred/TestSetupAndCleanupFailure.java  |    4 +-
 .../mapred/TestTrackerBlacklistAcrossJobs.java     |    2 +-
 .../org/apache/hadoop/mapred/UtilsForTests.java    |   34 +++++++++++++-------
 .../mapred/lib/TestCombineFileInputFormat.java     |    6 ++-
 .../lib/input/TestCombineFileInputFormat.java      |    6 ++-
 13 files changed, 51 insertions(+), 36 deletions(-)

diff --git a/src/test/org/apache/hadoop/mapred/TestFileInputFormat.java b/src/test/org/apache/hadoop/mapred/TestFileInputFormat.java
index bc1a279..b87744d 100644
--- a/src/test/org/apache/hadoop/mapred/TestFileInputFormat.java
+++ b/src/test/org/apache/hadoop/mapred/TestFileInputFormat.java
@@ -19,6 +19,7 @@ package org.apache.hadoop.mapred;
 
 import java.io.DataOutputStream;
 import java.io.IOException;
+import java.util.concurrent.TimeoutException;
 
 import junit.framework.TestCase;
 
@@ -86,7 +87,7 @@ public class TestFileInputFormat extends TestCase {
   }
 
   private void createInputs(FileSystem fs, Path inDir, String fileName) 
-  throws IOException {
+      throws IOException, TimeoutException, InterruptedException {
     // create a multi-block file on hdfs
     DataOutputStream out = fs.create(new Path(inDir, fileName), true, 4096, 
                                      (short) 2, 512, null);
diff --git a/src/test/org/apache/hadoop/mapred/TestJobInProgressListener.java b/src/test/org/apache/hadoop/mapred/TestJobInProgressListener.java
index d06e5d2..c429af4 100644
--- a/src/test/org/apache/hadoop/mapred/TestJobInProgressListener.java
+++ b/src/test/org/apache/hadoop/mapred/TestJobInProgressListener.java
@@ -62,7 +62,7 @@ public class TestJobInProgressListener extends TestCase {
    *   - check if the queue looks ok
    *   
    */
-  public void testJobQueueChanges() throws IOException {
+  public void testJobQueueChanges() throws Exception {
     LOG.info("Testing job queue changes");
     JobConf conf = new JobConf();
     MiniDFSCluster dfs = new MiniDFSCluster(conf, 1, true, null, null);
diff --git a/src/test/org/apache/hadoop/mapred/TestJobQueueInformation.java b/src/test/org/apache/hadoop/mapred/TestJobQueueInformation.java
index 0e5d56b..2572f34 100644
--- a/src/test/org/apache/hadoop/mapred/TestJobQueueInformation.java
+++ b/src/test/org/apache/hadoop/mapred/TestJobQueueInformation.java
@@ -102,7 +102,7 @@ public class TestJobQueueInformation extends TestCase {
     dfsCluster.shutdown();
   }
 
-  public void testJobQueues() throws IOException {
+  public void testJobQueues() throws Exception {
     JobClient jc = new JobClient(mrCluster.createJobConf());
     String expectedQueueInfo = "Maximum Tasks Per Job :: 10";
     JobQueueInfo[] queueInfos = jc.getQueues();
diff --git a/src/test/org/apache/hadoop/mapred/TestJobTrackerRestart.java b/src/test/org/apache/hadoop/mapred/TestJobTrackerRestart.java
index 4aa53db..48dfedc 100644
--- a/src/test/org/apache/hadoop/mapred/TestJobTrackerRestart.java
+++ b/src/test/org/apache/hadoop/mapred/TestJobTrackerRestart.java
@@ -102,7 +102,7 @@ public class TestJobTrackerRestart {
   @Test
   public void testRestartWithoutRecovery(MiniDFSCluster dfs, 
                                          MiniMRCluster mr) 
-  throws IOException {
+  throws Exception {
     // III. Test a job with waiting mapper and recovery turned off
     
     FileSystem fileSys = dfs.getFileSystem();
@@ -197,7 +197,7 @@ public class TestJobTrackerRestart {
   @Test
   public void testTaskEventsAndReportsWithRecovery(MiniDFSCluster dfs, 
                                                    MiniMRCluster mr) 
-  throws IOException {
+  throws Exception {
     // II. Test a tasktracker with waiting mapper and recovery turned on.
     //     Ideally the tracker should SYNC with the new/restarted jobtracker
     
@@ -412,7 +412,7 @@ public class TestJobTrackerRestart {
   @Test
   public void testJobRecoveryWithEmptyHistory(MiniDFSCluster dfs, 
                                               MiniMRCluster mr) 
-  throws IOException {
+  throws Exception {
     mr.startTaskTracker(null, null, 1, 1);
     FileSystem fileSys = dfs.getFileSystem();
     
@@ -502,7 +502,7 @@ public class TestJobTrackerRestart {
   }
   
   @Test
-  public void testJobTrackerRestart() throws IOException {
+  public void testJobTrackerRestart() throws Exception {
     String namenode = null;
     MiniDFSCluster dfs = null;
     MiniMRCluster mr = null;
@@ -577,7 +577,7 @@ public class TestJobTrackerRestart {
     return (new Path(dir, "jt-restart-reduce-signal")).toString();
   }
   
-  public static void main(String[] args) throws IOException {
+  public static void main(String[] args) throws Exception {
     new TestJobTrackerRestart().testJobTrackerRestart();
   }
 }
diff --git a/src/test/org/apache/hadoop/mapred/TestJobTrackerRestartWithLostTracker.java b/src/test/org/apache/hadoop/mapred/TestJobTrackerRestartWithLostTracker.java
index da43e6c..b2b42e1 100644
--- a/src/test/org/apache/hadoop/mapred/TestJobTrackerRestartWithLostTracker.java
+++ b/src/test/org/apache/hadoop/mapred/TestJobTrackerRestartWithLostTracker.java
@@ -48,7 +48,7 @@ public class TestJobTrackerRestartWithLostTracker extends TestCase {
   
   public void testRecoveryWithLostTracker(MiniDFSCluster dfs,
                                           MiniMRCluster mr) 
-  throws IOException {
+  throws Exception {
     FileSystem fileSys = dfs.getFileSystem();
     JobConf jobConf = mr.createJobConf();
     int numMaps = 2;
@@ -115,7 +115,7 @@ public class TestJobTrackerRestartWithLostTracker extends TestCase {
     assertTrue("Job should be successful", rJob.isSuccessful());
   }
   
-  public void testRestartWithLostTracker() throws IOException {
+  public void testRestartWithLostTracker() throws Exception {
     String namenode = null;
     MiniDFSCluster dfs = null;
     MiniMRCluster mr = null;
@@ -172,7 +172,7 @@ public class TestJobTrackerRestartWithLostTracker extends TestCase {
     }
   }
 
-  public static void main(String[] args) throws IOException {
+  public static void main(String[] args) throws Exception {
     new TestJobTrackerRestartWithLostTracker().testRestartWithLostTracker();
   }
 }
diff --git a/src/test/org/apache/hadoop/mapred/TestLostTracker.java b/src/test/org/apache/hadoop/mapred/TestLostTracker.java
index 2b46506..667cd76 100644
--- a/src/test/org/apache/hadoop/mapred/TestLostTracker.java
+++ b/src/test/org/apache/hadoop/mapred/TestLostTracker.java
@@ -44,7 +44,7 @@ public class TestLostTracker extends TestCase {
   
   public void testLostTracker(MiniDFSCluster dfs,
                               MiniMRCluster mr) 
-  throws IOException {
+  throws Exception {
     FileSystem fileSys = dfs.getFileSystem();
     JobConf jobConf = mr.createJobConf();
     int numMaps = 10;
@@ -141,7 +141,7 @@ public class TestLostTracker extends TestCase {
     }
   }
 
-  public void testLostTracker() throws IOException {
+  public void testLostTracker() throws Exception {
     String namenode = null;
     MiniDFSCluster dfs = null;
     MiniMRCluster mr = null;
@@ -195,7 +195,7 @@ public class TestLostTracker extends TestCase {
     }
   }
 
-  public static void main(String[] args) throws IOException {
+  public static void main(String[] args) throws Exception {
     new TestLostTracker().testLostTracker();
   }
 }
diff --git a/src/test/org/apache/hadoop/mapred/TestMultipleLevelCaching.java b/src/test/org/apache/hadoop/mapred/TestMultipleLevelCaching.java
index 40706b3..68264d3 100644
--- a/src/test/org/apache/hadoop/mapred/TestMultipleLevelCaching.java
+++ b/src/test/org/apache/hadoop/mapred/TestMultipleLevelCaching.java
@@ -64,13 +64,13 @@ public class TestMultipleLevelCaching extends TestCase {
     return rack.toString();
   }
 
-  public void testMultiLevelCaching() throws IOException {
+  public void testMultiLevelCaching() throws Exception {
     for (int i = 1 ; i <= MAX_LEVEL; ++i) {
       testCachingAtLevel(i);
     }
   }
 
-  private void testCachingAtLevel(int level) throws IOException {
+  private void testCachingAtLevel(int level) throws Exception {
     String namenode = null;
     MiniDFSCluster dfs = null;
     MiniMRCluster mr = null;
diff --git a/src/test/org/apache/hadoop/mapred/TestRackAwareTaskPlacement.java b/src/test/org/apache/hadoop/mapred/TestRackAwareTaskPlacement.java
index 9484695..5e9cc4e 100644
--- a/src/test/org/apache/hadoop/mapred/TestRackAwareTaskPlacement.java
+++ b/src/test/org/apache/hadoop/mapred/TestRackAwareTaskPlacement.java
@@ -87,7 +87,7 @@ public class TestRackAwareTaskPlacement extends TestCase {
     mr.shutdown();
   }
 
-  public void testTaskPlacement() throws IOException {
+  public void testTaskPlacement() throws Exception {
     String namenode = null;
     MiniDFSCluster dfs = null;
     MiniMRCluster mr = null;
diff --git a/src/test/org/apache/hadoop/mapred/TestSetupAndCleanupFailure.java b/src/test/org/apache/hadoop/mapred/TestSetupAndCleanupFailure.java
index 8c89413..0c35da8 100644
--- a/src/test/org/apache/hadoop/mapred/TestSetupAndCleanupFailure.java
+++ b/src/test/org/apache/hadoop/mapred/TestSetupAndCleanupFailure.java
@@ -178,7 +178,7 @@ public class TestSetupAndCleanupFailure extends TestCase {
   private void testSetupAndCleanupKill(MiniMRCluster mr, 
                                        MiniDFSCluster dfs, 
                                        boolean commandLineKill) 
-  throws IOException {
+  throws Exception {
     // launch job with waiting setup/cleanup
     RunningJob job = launchJobWithWaitingSetupAndCleanup(mr);
     
@@ -253,7 +253,7 @@ public class TestSetupAndCleanupFailure extends TestCase {
   // Also Tests the command-line kill for setup/cleanup attempts. 
   // tests the setup/cleanup attempts getting killed if 
   // they were running on a lost tracker
-  public void testWithDFS() throws IOException {
+  public void testWithDFS() throws Exception {
     MiniDFSCluster dfs = null;
     MiniMRCluster mr = null;
     FileSystem fileSys = null;
diff --git a/src/test/org/apache/hadoop/mapred/TestTrackerBlacklistAcrossJobs.java b/src/test/org/apache/hadoop/mapred/TestTrackerBlacklistAcrossJobs.java
index 5196551..26a85a5 100644
--- a/src/test/org/apache/hadoop/mapred/TestTrackerBlacklistAcrossJobs.java
+++ b/src/test/org/apache/hadoop/mapred/TestTrackerBlacklistAcrossJobs.java
@@ -56,7 +56,7 @@ public class TestTrackerBlacklistAcrossJobs extends TestCase {
     }
   }
   
-  public void testBlacklistAcrossJobs() throws IOException {
+  public void testBlacklistAcrossJobs() throws Exception {
     MiniDFSCluster dfs = null;
     MiniMRCluster mr = null;
     FileSystem fileSys = null;
diff --git a/src/test/org/apache/hadoop/mapred/UtilsForTests.java b/src/test/org/apache/hadoop/mapred/UtilsForTests.java
index 5138a25..4786cbc 100644
--- a/src/test/org/apache/hadoop/mapred/UtilsForTests.java
+++ b/src/test/org/apache/hadoop/mapred/UtilsForTests.java
@@ -28,6 +28,7 @@ import java.util.Iterator;
 import java.util.List;
 import java.util.Enumeration;
 import java.util.Properties;
+import java.util.concurrent.TimeoutException;
 
 import org.apache.commons.logging.LogFactory;
 import org.apache.commons.logging.Log;
@@ -499,11 +500,15 @@ public class UtilsForTests {
   static void signalTasks(MiniDFSCluster dfs, FileSystem fileSys, 
                           String mapSignalFile, 
                           String reduceSignalFile, int replication) 
-  throws IOException {
-    writeFile(dfs.getNameNode(), fileSys.getConf(), new Path(mapSignalFile), 
-              (short)replication);
-    writeFile(dfs.getNameNode(), fileSys.getConf(), new Path(reduceSignalFile), 
-              (short)replication);
+  throws IOException, TimeoutException {
+    try {
+      writeFile(dfs.getNameNode(), fileSys.getConf(), new Path(mapSignalFile), 
+                (short)replication);
+      writeFile(dfs.getNameNode(), fileSys.getConf(), new Path(reduceSignalFile), 
+                (short)replication);
+    } catch (InterruptedException ie) {
+      // Ignore
+    }
   }
   
   /**
@@ -512,12 +517,16 @@ public class UtilsForTests {
   static void signalTasks(MiniDFSCluster dfs, FileSystem fileSys, 
                           boolean isMap, String mapSignalFile, 
                           String reduceSignalFile)
-  throws IOException {
-    //  signal the maps to complete
-    writeFile(dfs.getNameNode(), fileSys.getConf(),
-              isMap 
-              ? new Path(mapSignalFile)
-              : new Path(reduceSignalFile), (short)1);
+  throws IOException, TimeoutException {
+    try {
+      //  signal the maps to complete
+      writeFile(dfs.getNameNode(), fileSys.getConf(),
+                isMap 
+                ? new Path(mapSignalFile)
+                : new Path(reduceSignalFile), (short)1);
+    } catch (InterruptedException ie) {
+      // Ignore
+    }
   }
   
   static String getSignalFile(Path dir) {
@@ -533,7 +542,8 @@ public class UtilsForTests {
   }
   
   static void writeFile(NameNode namenode, Configuration conf, Path name, 
-      short replication) throws IOException {
+                        short replication)
+      throws IOException, TimeoutException, InterruptedException {
     FileSystem fileSys = FileSystem.get(conf);
     SequenceFile.Writer writer = 
       SequenceFile.createWriter(fileSys, conf, name, 
diff --git a/src/test/org/apache/hadoop/mapred/lib/TestCombineFileInputFormat.java b/src/test/org/apache/hadoop/mapred/lib/TestCombineFileInputFormat.java
index 8f7c4be..ce5fce2 100644
--- a/src/test/org/apache/hadoop/mapred/lib/TestCombineFileInputFormat.java
+++ b/src/test/org/apache/hadoop/mapred/lib/TestCombineFileInputFormat.java
@@ -18,6 +18,7 @@
 package org.apache.hadoop.mapred.lib;
 
 import java.io.IOException;
+import java.util.concurrent.TimeoutException;
 
 import junit.framework.TestCase;
 
@@ -79,7 +80,7 @@ public class TestCombineFileInputFormat extends TestCase{
     }
   }
 
-  public void testSplitPlacement() throws IOException {
+  public void testSplitPlacement() throws Exception {
     String namenode = null;
     MiniDFSCluster dfs = null;
     MiniMRCluster mr = null;
@@ -438,7 +439,8 @@ public class TestCombineFileInputFormat extends TestCase{
   }
 
   static void writeFile(Configuration conf, Path name,
-      short replication, int numBlocks) throws IOException {
+      short replication, int numBlocks)
+      throws IOException, TimeoutException, InterruptedException {
     FileSystem fileSys = FileSystem.get(conf);
 
     FSDataOutputStream stm = fileSys.create(name, true,
diff --git a/src/test/org/apache/hadoop/mapreduce/lib/input/TestCombineFileInputFormat.java b/src/test/org/apache/hadoop/mapreduce/lib/input/TestCombineFileInputFormat.java
index bf89286..216268d 100644
--- a/src/test/org/apache/hadoop/mapreduce/lib/input/TestCombineFileInputFormat.java
+++ b/src/test/org/apache/hadoop/mapreduce/lib/input/TestCombineFileInputFormat.java
@@ -20,6 +20,7 @@ package org.apache.hadoop.mapreduce.lib.input;
 import java.io.IOException;
 import java.util.List;
 import java.util.ArrayList;
+import java.util.concurrent.TimeoutException;
 
 import junit.framework.TestCase;
 
@@ -240,7 +241,7 @@ public class TestCombineFileInputFormat extends TestCase {
     assertFalse(rr.nextKeyValue());
   }
 
-  public void testSplitPlacement() throws IOException {
+  public void testSplitPlacement() throws Exception {
     MiniDFSCluster dfs = null;
     FileSystem fileSys = null;
     try {
@@ -605,7 +606,8 @@ public class TestCombineFileInputFormat extends TestCase {
   }
 
   static void writeFile(Configuration conf, Path name,
-      short replication, int numBlocks) throws IOException {
+      short replication, int numBlocks)
+      throws IOException, TimeoutException, InterruptedException {
     FileSystem fileSys = FileSystem.get(conf);
 
     FSDataOutputStream stm = fileSys.create(name, true,
-- 
1.7.0.4

