From cd32c2af4655b9a3ddc0fa841df67cabd3648f37 Mon Sep 17 00:00:00 2001
From: Todd Lipcon <todd@apache.org>
Date: Tue, 15 Jan 2013 00:31:35 +0000
Subject: [PATCH 0856/1357] HDFS-4402. Some small DomainSocket fixes: avoid findbugs warning, change log level, etc. Contributed by Colin Patrick McCabe.

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1433242 13f79535-47bb-0310-9956-ffa450edef68
(cherry picked from commit 7f0452f515fe83cb3bf7c9f2322b1ca4dc6e8ef6)
---
 .../org/apache/hadoop/net/unix/DomainSocket.java   |    2 +-
 .../hadoop-hdfs/CHANGES.HDFS-347.txt               |    3 +++
 .../org/apache/hadoop/hdfs/BlockReaderLocal.java   |    6 +++++-
 .../apache/hadoop/hdfs/DomainSocketFactory.java    |    6 +++---
 .../apache/hadoop/hdfs/FileInputStreamCache.java   |    1 -
 5 files changed, 12 insertions(+), 6 deletions(-)

diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/unix/DomainSocket.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/unix/DomainSocket.java
index 9c37db3..034ac3b 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/unix/DomainSocket.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/unix/DomainSocket.java
@@ -254,7 +254,7 @@ public class DomainSocket implements Closeable {
   private void fdUnref(boolean checkClosed) throws AsynchronousCloseException {
     int newCount = status.decrementAndGet();
     assert (newCount & ~STATUS_CLOSED_MASK) >= 0;
-    if (checkClosed & ((newCount & STATUS_CLOSED_MASK) != 0)) {
+    if (checkClosed && ((newCount & STATUS_CLOSED_MASK) != 0)) {
       throw new AsynchronousCloseException();
     }
   }
diff --git a/hadoop-hdfs-project/hadoop-hdfs/CHANGES.HDFS-347.txt b/hadoop-hdfs-project/hadoop-hdfs/CHANGES.HDFS-347.txt
index 96afb6a..afc04b4 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/CHANGES.HDFS-347.txt
+++ b/hadoop-hdfs-project/hadoop-hdfs/CHANGES.HDFS-347.txt
@@ -22,3 +22,6 @@ HDFS-4400. DFSInputStream#getBlockReader: last retries should ignore the cache
 
 HDFS-4401. Fix bug in DomainSocket path validation
 (Colin Patrick McCabe via todd)
+
+HDFS-4402. Some small DomainSocket fixes: avoid findbugs warning, change log level, etc.
+(Colin Patrick McCabe via todd)
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java
index 1c34a71..ca9ce08 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/BlockReaderLocal.java
@@ -19,6 +19,8 @@ package org.apache.hadoop.hdfs;
 
 import java.io.DataInputStream;
 import org.apache.hadoop.conf.Configuration;
+
+import java.io.BufferedInputStream;
 import java.io.FileInputStream;
 import java.io.IOException;
 import java.nio.ByteBuffer;
@@ -118,7 +120,9 @@ class BlockReaderLocal implements BlockReader {
     // read and handle the common header here. For now just a version
     checksumIn.getChannel().position(0);
     BlockMetadataHeader header = BlockMetadataHeader
-        .readHeader(new DataInputStream(checksumIn));
+        .readHeader(new DataInputStream(
+            new BufferedInputStream(checksumIn,
+                BlockMetadataHeader.getHeaderSize())));
     short version = header.getVersion();
     if (version != BlockMetadataHeader.VERSION) {
       throw new IOException("Wrong version (" + version + ") of the " +
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DomainSocketFactory.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DomainSocketFactory.java
index 50b6052..db9afc1 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DomainSocketFactory.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DomainSocketFactory.java
@@ -62,7 +62,7 @@ class DomainSocketFactory {
         LOG.warn(feature + " is disabled because you have not set " +
             DFSConfigKeys.DFS_DATANODE_DOMAIN_SOCKET_PATH_KEY);
       } else if (DomainSocket.getLoadingFailureReason() != null) {
-        LOG.error(feature + " is disabled because " +
+        LOG.warn(feature + " is disabled because " +
               DomainSocket.getLoadingFailureReason());
       } else {
         LOG.debug(feature + "is enabled.");
@@ -113,7 +113,7 @@ class DomainSocketFactory {
       sock.setAttribute(DomainSocket.RCV_TIMEO, conf.socketTimeout);
       success = true;
     } catch (IOException e) {
-      LOG.error("error creating DomainSocket", e);
+      LOG.warn("error creating DomainSocket", e);
       // fall through
     } finally {
       if (!success) {
@@ -134,4 +134,4 @@ class DomainSocketFactory {
   public void disableDomainSocketPath(String path) {
     pathInfo.put(path, PathStatus.UNUSABLE);
   }
-}
\ No newline at end of file
+}
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/FileInputStreamCache.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/FileInputStreamCache.java
index d9045f0..ac0af81 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/FileInputStreamCache.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/FileInputStreamCache.java
@@ -22,7 +22,6 @@ import java.util.Iterator;
 import java.util.List;
 import java.util.Map.Entry;
 import java.util.concurrent.ScheduledThreadPoolExecutor;
-import java.util.concurrent.ThreadFactory;
 import java.util.concurrent.TimeUnit;
 
 import org.apache.commons.logging.Log;
-- 
1.7.0.4

